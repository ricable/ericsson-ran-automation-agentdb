#!/usr/bin/env node
/**
 * Agentic Flow - Standalone CLI with integrated OpenRouter proxy
 * Usage: npx agentic-flow-proxy --agent coder --task "Create code" --openrouter
 */
import dotenv from "dotenv";
import { existsSync, readFileSync } from 'fs';
import { resolve as pathResolve, dirname } from 'path';
import { fileURLToPath } from 'url';
// Load .env from current directory, or search up the directory tree
function loadEnvRecursive(startPath = process.cwd()) {
    let currentPath = startPath;
    const root = pathResolve('/');
    while (currentPath !== root) {
        const envPath = pathResolve(currentPath, '.env');
        if (existsSync(envPath)) {
            dotenv.config({ path: envPath });
            return true;
        }
        currentPath = pathResolve(currentPath, '..');
    }
    // Fallback to default behavior
    dotenv.config();
    return false;
}
loadEnvRecursive();
import { AnthropicToOpenRouterProxy } from "./proxy/anthropic-to-openrouter.js";
import { AnthropicToRequestyProxy } from "./proxy/anthropic-to-requesty.js";
import { logger } from "./utils/logger.js";
import { parseArgs } from "./utils/cli.js";
import { getAgent, listAgents } from "./utils/agentLoader.js";
import { claudeAgent } from "./agents/claudeAgent.js";
import { handleReasoningBankCommand } from "./utils/reasoningbankCommands.js";
import { handleConfigCommand } from "./cli/config-wizard.js";
import { handleAgentCommand } from "./cli/agent-manager.js";
import { ModelOptimizer } from "./utils/modelOptimizer.js";
import { detectModelCapabilities } from "./utils/modelCapabilities.js";
import { AgentBoosterPreprocessor } from "./utils/agentBoosterPreprocessor.js";
const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);
const packageJson = JSON.parse(readFileSync(pathResolve(__dirname, '../package.json'), 'utf-8'));
const VERSION = packageJson.version;
class AgenticFlowCLI {
    proxyServer = null;
    proxyPort = 3000;
    async start() {
        const options = parseArgs();
        if (options.version) {
            console.log(`agentic-flow v${VERSION}`);
            process.exit(0);
        }
        if (options.help) {
            this.printHelp();
            process.exit(0);
        }
        // If no mode and no agent specified, show help
        if (!options.agent && options.mode !== 'list' && !['config', 'agent-manager', 'mcp-manager', 'proxy', 'quic', 'claude-code', 'mcp', 'reasoningbank'].includes(options.mode)) {
            this.printHelp();
            process.exit(0);
        }
        if (options.mode === 'list') {
            this.listAgents();
            process.exit(0);
        }
        if (options.mode === 'config') {
            // Handle config wizard
            const configArgs = process.argv.slice(3); // Skip 'node', 'cli-proxy.js', 'config'
            await handleConfigCommand(configArgs);
            process.exit(0);
        }
        if (options.mode === 'agent-manager') {
            // Handle agent management commands
            const agentArgs = process.argv.slice(3); // Skip 'node', 'cli-proxy.js', 'agent'
            await handleAgentCommand(agentArgs);
            process.exit(0);
        }
        if (options.mode === 'mcp-manager') {
            // Handle MCP manager commands (add, list, remove, etc.)
            const { spawn } = await import('child_process');
            const { resolve, dirname } = await import('path');
            const { fileURLToPath } = await import('url');
            const __filename = fileURLToPath(import.meta.url);
            const __dirname = dirname(__filename);
            const mcpManagerPath = resolve(__dirname, './cli/mcp-manager.js');
            // Pass all args after 'mcp' to mcp-manager
            const mcpArgs = process.argv.slice(3); // Skip 'node', 'cli-proxy.js', 'mcp'
            const proc = spawn('node', [mcpManagerPath, ...mcpArgs], {
                stdio: 'inherit'
            });
            proc.on('exit', (code) => {
                process.exit(code || 0);
            });
            process.on('SIGINT', () => proc.kill('SIGINT'));
            process.on('SIGTERM', () => proc.kill('SIGTERM'));
            return;
        }
        if (options.mode === 'proxy') {
            // Run standalone proxy server for Claude Code/Cursor
            await this.runStandaloneProxy();
            return;
        }
        if (options.mode === 'quic') {
            // Run QUIC transport proxy server
            await this.runQuicProxy();
            return;
        }
        if (options.mode === 'claude-code') {
            // Spawn Claude Code with auto-configured proxy
            const { spawn } = await import('child_process');
            const claudeCodePath = pathResolve(__dirname, './cli/claude-code-wrapper.js');
            const proc = spawn('node', [claudeCodePath, ...process.argv.slice(3)], {
                stdio: 'inherit',
                env: process.env
            });
            proc.on('exit', (code) => {
                process.exit(code || 0);
            });
            process.on('SIGINT', () => proc.kill('SIGINT'));
            process.on('SIGTERM', () => proc.kill('SIGTERM'));
            return;
        }
        if (options.mode === 'mcp') {
            // Run standalone MCP server directly
            const { spawn } = await import('child_process');
            const { resolve, dirname } = await import('path');
            const { fileURLToPath } = await import('url');
            const __filename = fileURLToPath(import.meta.url);
            const __dirname = dirname(__filename);
            const serverPath = resolve(__dirname, './mcp/standalone-stdio.js');
            const proc = spawn('node', [serverPath], {
                stdio: 'inherit'
            });
            proc.on('exit', (code) => {
                process.exit(code || 0);
            });
            // Handle termination signals
            process.on('SIGINT', () => proc.kill('SIGINT'));
            process.on('SIGTERM', () => proc.kill('SIGTERM'));
            return;
        }
        if (options.mode === 'reasoningbank') {
            // Handle ReasoningBank commands
            const subcommand = process.argv[3] || 'help';
            await handleReasoningBankCommand(subcommand);
            process.exit(0);
        }
        // Apply model optimization if requested
        if (options.optimize && options.agent && options.task) {
            const recommendation = ModelOptimizer.optimize({
                agent: options.agent,
                task: options.task,
                priority: options.optimizePriority || 'balanced',
                maxCostPerTask: options.maxCost,
                requiresTools: true // Agents have MCP tools available, so require tool support
            });
            // Display recommendation
            ModelOptimizer.displayRecommendation(recommendation);
            // Apply recommendation to options
            if (!options.provider || options.optimize) {
                options.provider = recommendation.provider;
            }
            if (!options.model || options.optimize) {
                options.model = recommendation.model;
            }
            console.log(`‚úÖ Using optimized model: ${recommendation.modelName}\n`);
        }
        // Determine which provider to use
        const useONNX = this.shouldUseONNX(options);
        const useOpenRouter = this.shouldUseOpenRouter(options);
        const useGemini = this.shouldUseGemini(options);
        // Requesty temporarily disabled - keep proxy files for future use
        const useRequesty = false; // this.shouldUseRequesty(options);
        // Debug output for provider selection
        if (options.verbose || process.env.VERBOSE === 'true') {
            console.log('\nüîç Provider Selection Debug:');
            console.log(`  Provider flag: ${options.provider || 'not set'}`);
            console.log(`  Model: ${options.model || 'default'}`);
            console.log(`  Use ONNX: ${useONNX}`);
            console.log(`  Use OpenRouter: ${useOpenRouter}`);
            console.log(`  Use Gemini: ${useGemini}`);
            console.log(`  Use Requesty: ${useRequesty}`);
            console.log(`  OPENROUTER_API_KEY: ${process.env.OPENROUTER_API_KEY ? '‚úì set' : '‚úó not set'}`);
            console.log(`  GOOGLE_GEMINI_API_KEY: ${process.env.GOOGLE_GEMINI_API_KEY ? '‚úì set' : '‚úó not set'}`);
            console.log(`  REQUESTY_API_KEY: ${process.env.REQUESTY_API_KEY ? '‚úì set' : '‚úó not set'}`);
            console.log(`  ANTHROPIC_API_KEY: ${process.env.ANTHROPIC_API_KEY ? '‚úì set' : '‚úó not set'}\n`);
        }
        try {
            // Start proxy if needed (ONNX, OpenRouter, Gemini, or Requesty)
            if (useONNX) {
                console.log('üöÄ Initializing ONNX local inference proxy...');
                await this.startONNXProxy(options.model);
            }
            else if (useRequesty) {
                console.log('üöÄ Initializing Requesty proxy...');
                await this.startRequestyProxy(options.model);
            }
            else if (useOpenRouter) {
                console.log('üöÄ Initializing OpenRouter proxy...');
                await this.startOpenRouterProxy(options.model);
            }
            else if (useGemini) {
                console.log('üöÄ Initializing Gemini proxy...');
                await this.startGeminiProxy(options.model);
            }
            else {
                console.log('üöÄ Using direct Anthropic API...\n');
            }
            // Run agent
            await this.runAgent(options, useOpenRouter, useGemini, useONNX, useRequesty);
            logger.info('Execution completed successfully');
            process.exit(0);
        }
        catch (err) {
            logger.error('Execution failed', { error: err });
            console.error(err);
            process.exit(1);
        }
    }
    shouldUseONNX(options) {
        // Use ONNX if:
        // 1. Provider is explicitly set to onnx
        // 2. PROVIDER env var is set to onnx
        // 3. USE_ONNX env var is set
        if (options.provider === 'onnx' || process.env.PROVIDER === 'onnx') {
            return true;
        }
        if (process.env.USE_ONNX === 'true') {
            return true;
        }
        return false;
    }
    shouldUseGemini(options) {
        // Use Gemini if:
        // 1. Provider is explicitly set to gemini
        // 2. PROVIDER env var is set to gemini
        // 3. USE_GEMINI env var is set
        // 4. GOOGLE_GEMINI_API_KEY is set and no other provider is specified
        if (options.provider === 'gemini' || process.env.PROVIDER === 'gemini') {
            return true;
        }
        if (process.env.USE_GEMINI === 'true') {
            return true;
        }
        if (process.env.GOOGLE_GEMINI_API_KEY &&
            !process.env.ANTHROPIC_API_KEY &&
            !process.env.OPENROUTER_API_KEY &&
            options.provider !== 'onnx') {
            return true;
        }
        return false;
    }
    shouldUseRequesty(options) {
        // Use Requesty if:
        // 1. Provider is explicitly set to requesty
        // 2. PROVIDER env var is set to requesty
        // 3. USE_REQUESTY env var is set
        if (options.provider === 'requesty' || process.env.PROVIDER === 'requesty') {
            return true;
        }
        if (process.env.USE_REQUESTY === 'true') {
            return true;
        }
        return false;
    }
    shouldUseOpenRouter(options) {
        // Don't use OpenRouter if ONNX, Gemini, or Requesty is explicitly requested
        if (options.provider === 'onnx' || process.env.USE_ONNX === 'true' || process.env.PROVIDER === 'onnx') {
            return false;
        }
        if (options.provider === 'gemini' || process.env.PROVIDER === 'gemini') {
            return false;
        }
        if (options.provider === 'requesty' || process.env.PROVIDER === 'requesty') {
            return false;
        }
        // Use OpenRouter if:
        // 1. Provider is explicitly set to openrouter
        // 2. Model parameter contains "/" (e.g., "meta-llama/llama-3.1-8b-instruct")
        // 3. USE_OPENROUTER env var is set
        // 4. OPENROUTER_API_KEY is set and ANTHROPIC_API_KEY is not
        if (options.provider === 'openrouter' || process.env.PROVIDER === 'openrouter') {
            return true;
        }
        if (options.model?.includes('/')) {
            return true;
        }
        if (process.env.USE_OPENROUTER === 'true') {
            return true;
        }
        if (process.env.OPENROUTER_API_KEY && !process.env.ANTHROPIC_API_KEY && !process.env.GOOGLE_GEMINI_API_KEY) {
            return true;
        }
        return false;
    }
    async startOpenRouterProxy(modelOverride) {
        const openrouterKey = process.env.OPENROUTER_API_KEY;
        if (!openrouterKey) {
            console.error('‚ùå Error: OPENROUTER_API_KEY required for OpenRouter models');
            console.error('Set it in .env or export OPENROUTER_API_KEY=sk-or-v1-xxxxx');
            process.exit(1);
        }
        logger.info('Starting integrated OpenRouter proxy');
        const defaultModel = modelOverride ||
            process.env.COMPLETION_MODEL ||
            process.env.REASONING_MODEL ||
            'deepseek/deepseek-chat';
        const capabilities = detectModelCapabilities(defaultModel);
        const proxy = new AnthropicToOpenRouterProxy({
            openrouterApiKey: openrouterKey,
            openrouterBaseUrl: process.env.ANTHROPIC_PROXY_BASE_URL,
            defaultModel,
            capabilities: capabilities
        });
        // Start proxy in background
        proxy.start(this.proxyPort);
        this.proxyServer = proxy;
        // Set ANTHROPIC_BASE_URL to proxy
        process.env.ANTHROPIC_BASE_URL = `http://localhost:${this.proxyPort}`;
        // Set dummy ANTHROPIC_API_KEY for proxy (actual auth uses OPENROUTER_API_KEY)
        if (!process.env.ANTHROPIC_API_KEY) {
            process.env.ANTHROPIC_API_KEY = 'sk-ant-proxy-dummy-key';
        }
        console.log(`üîó Proxy Mode: OpenRouter`);
        console.log(`üîß Proxy URL: http://localhost:${this.proxyPort}`);
        console.log(`ü§ñ Default Model: ${defaultModel}`);
        if (capabilities.requiresEmulation) {
            console.log(`\n‚öôÔ∏è  Detected: Model lacks native tool support`);
            console.log(`üîß Using ${capabilities.emulationStrategy.toUpperCase()} emulation pattern`);
            console.log(`üìä Expected reliability: ${capabilities.emulationStrategy === 'react' ? '70-85%' : '50-70%'}`);
        }
        console.log('');
        // Wait for proxy to be ready
        await new Promise(resolve => setTimeout(resolve, 1500));
    }
    async startGeminiProxy(modelOverride) {
        const geminiKey = process.env.GOOGLE_GEMINI_API_KEY;
        if (!geminiKey) {
            console.error('‚ùå Error: GOOGLE_GEMINI_API_KEY required for Gemini models');
            console.error('Set it in .env or export GOOGLE_GEMINI_API_KEY=xxxxx');
            process.exit(1);
        }
        logger.info('Starting integrated Gemini proxy');
        const defaultModel = modelOverride ||
            process.env.COMPLETION_MODEL ||
            'gemini-2.0-flash-exp';
        // Import Gemini proxy
        const { AnthropicToGeminiProxy } = await import('./proxy/anthropic-to-gemini.js');
        const proxy = new AnthropicToGeminiProxy({
            geminiApiKey: geminiKey,
            defaultModel
        });
        // Start proxy in background
        proxy.start(this.proxyPort);
        this.proxyServer = proxy;
        // Set ANTHROPIC_BASE_URL to proxy
        process.env.ANTHROPIC_BASE_URL = `http://localhost:${this.proxyPort}`;
        // Set dummy ANTHROPIC_API_KEY for proxy (actual auth uses GOOGLE_GEMINI_API_KEY)
        if (!process.env.ANTHROPIC_API_KEY) {
            process.env.ANTHROPIC_API_KEY = 'sk-ant-proxy-dummy-key';
        }
        console.log(`üîó Proxy Mode: Google Gemini`);
        console.log(`üîß Proxy URL: http://localhost:${this.proxyPort}`);
        console.log(`ü§ñ Default Model: ${defaultModel}\n`);
        // Wait for proxy to be ready
        await new Promise(resolve => setTimeout(resolve, 1500));
    }
    async startRequestyProxy(modelOverride) {
        const requestyKey = process.env.REQUESTY_API_KEY;
        if (!requestyKey) {
            console.error('‚ùå Error: REQUESTY_API_KEY required for Requesty models');
            console.error('Set it in .env or export REQUESTY_API_KEY=sk-xxxxx');
            process.exit(1);
        }
        logger.info('Starting integrated Requesty proxy');
        const defaultModel = modelOverride ||
            process.env.COMPLETION_MODEL ||
            process.env.REASONING_MODEL ||
            'deepseek/deepseek-chat';
        const capabilities = detectModelCapabilities(defaultModel);
        const proxy = new AnthropicToRequestyProxy({
            requestyApiKey: requestyKey,
            requestyBaseUrl: process.env.REQUESTY_BASE_URL,
            defaultModel,
            capabilities: capabilities
        });
        // Start proxy in background
        proxy.start(this.proxyPort);
        this.proxyServer = proxy;
        // Set ANTHROPIC_BASE_URL to proxy
        process.env.ANTHROPIC_BASE_URL = `http://localhost:${this.proxyPort}`;
        // Set dummy ANTHROPIC_API_KEY for proxy (actual auth uses REQUESTY_API_KEY)
        if (!process.env.ANTHROPIC_API_KEY) {
            process.env.ANTHROPIC_API_KEY = 'sk-ant-proxy-dummy-key';
        }
        console.log(`üîó Proxy Mode: Requesty`);
        console.log(`üîß Proxy URL: http://localhost:${this.proxyPort}`);
        console.log(`ü§ñ Default Model: ${defaultModel}`);
        if (capabilities.requiresEmulation) {
            console.log(`\n‚öôÔ∏è  Detected: Model lacks native tool support`);
            console.log(`üîß Using ${capabilities.emulationStrategy.toUpperCase()} emulation pattern`);
            console.log(`üìä Expected reliability: ${capabilities.emulationStrategy === 'react' ? '70-85%' : '50-70%'}`);
        }
        console.log('');
        // Wait for proxy to be ready
        await new Promise(resolve => setTimeout(resolve, 1500));
    }
    async startONNXProxy(modelOverride) {
        logger.info('Starting integrated ONNX local inference proxy');
        console.log('üîß Provider: ONNX Local (Phi-4-mini)');
        console.log('üíæ Free local inference - no API costs\n');
        // Import ONNX proxy
        const { AnthropicToONNXProxy } = await import('./proxy/anthropic-to-onnx.js');
        // Use a different port for ONNX to avoid conflicts
        const onnxProxyPort = parseInt(process.env.ONNX_PROXY_PORT || '3001');
        const proxy = new AnthropicToONNXProxy({
            port: onnxProxyPort,
            modelPath: process.env.ONNX_MODEL_PATH,
            executionProviders: process.env.ONNX_EXECUTION_PROVIDERS?.split(',') || ['cpu']
        });
        // Start proxy in background
        await proxy.start();
        this.proxyServer = proxy;
        // Set ANTHROPIC_BASE_URL to ONNX proxy
        process.env.ANTHROPIC_BASE_URL = `http://localhost:${onnxProxyPort}`;
        // Set dummy ANTHROPIC_API_KEY for proxy (local inference doesn't need key)
        if (!process.env.ANTHROPIC_API_KEY) {
            process.env.ANTHROPIC_API_KEY = 'sk-ant-onnx-local-key';
        }
        console.log(`üîó Proxy Mode: ONNX Local Inference`);
        console.log(`üîß Proxy URL: http://localhost:${onnxProxyPort}`);
        console.log(`ü§ñ Model: Phi-4-mini-instruct (ONNX)\n`);
        // Wait for proxy to be ready and model to load
        console.log('‚è≥ Loading ONNX model... (this may take a moment)\n');
        await new Promise(resolve => setTimeout(resolve, 2000));
    }
    async runStandaloneProxy() {
        const args = process.argv.slice(3); // Skip 'node', 'cli-proxy.js', 'proxy'
        // Parse proxy arguments
        let provider = 'gemini';
        let port = 3000;
        let model;
        for (let i = 0; i < args.length; i++) {
            if ((args[i] === '--provider' || args[i] === '-p') && args[i + 1]) {
                provider = args[++i];
            }
            else if ((args[i] === '--port' || args[i] === '-P') && args[i + 1]) {
                port = parseInt(args[++i]);
            }
            else if ((args[i] === '--model' || args[i] === '-m') && args[i + 1]) {
                model = args[++i];
            }
            else if (args[i] === '--help' || args[i] === '-h') {
                this.printProxyHelp();
                process.exit(0);
            }
        }
        console.log(`
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë   Agentic Flow - Standalone Anthropic Proxy Server    ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
`);
        if (provider === 'gemini') {
            const apiKey = process.env.GOOGLE_GEMINI_API_KEY;
            if (!apiKey) {
                console.error(`‚ùå Error: GOOGLE_GEMINI_API_KEY environment variable required

Set it with:
  export GOOGLE_GEMINI_API_KEY=your-key-here
`);
                process.exit(1);
            }
            const finalModel = model || process.env.COMPLETION_MODEL || 'gemini-2.0-flash-exp';
            console.log(`üöÄ Starting Gemini ‚Üí Anthropic Proxy
üìç Port: ${port}
ü§ñ Model: ${finalModel}
üîó Gemini API: https://generativelanguage.googleapis.com
`);
            const { AnthropicToGeminiProxy } = await import('./proxy/anthropic-to-gemini.js');
            const proxy = new AnthropicToGeminiProxy({
                geminiApiKey: apiKey,
                defaultModel: finalModel
            });
            proxy.start(port);
            console.log(`‚úÖ Proxy server running!

Configure Claude Code:
  export ANTHROPIC_BASE_URL=http://localhost:${port}
  export ANTHROPIC_API_KEY=sk-ant-proxy-dummy-key
  claude

Cost Savings: ~85% vs direct Anthropic API
`);
        }
        else if (provider === 'openrouter') {
            const apiKey = process.env.OPENROUTER_API_KEY;
            if (!apiKey) {
                console.error(`‚ùå Error: OPENROUTER_API_KEY environment variable required

Set it with:
  export OPENROUTER_API_KEY=sk-or-v1-your-key-here

Get your key at: https://openrouter.ai/keys
`);
                process.exit(1);
            }
            const finalModel = model || process.env.COMPLETION_MODEL || 'deepseek/deepseek-chat';
            console.log(`üöÄ Starting OpenRouter ‚Üí Anthropic Proxy
üìç Port: ${port}
ü§ñ Model: ${finalModel}
üîó OpenRouter API: https://openrouter.ai/api/v1
`);
            const { AnthropicToOpenRouterProxy } = await import('./proxy/anthropic-to-openrouter.js');
            const proxy = new AnthropicToOpenRouterProxy({
                openrouterApiKey: apiKey,
                defaultModel: finalModel
            });
            proxy.start(port);
            console.log(`‚úÖ Proxy server running!

Configure Claude Code:
  export ANTHROPIC_BASE_URL=http://localhost:${port}
  export ANTHROPIC_API_KEY=sk-ant-proxy-dummy-key
  claude

Cost Savings: ~90% vs direct Anthropic API
Popular Models:
  - openai/gpt-4o-mini (fast, cheap)
  - anthropic/claude-3.5-sonnet (via OpenRouter)
  - meta-llama/llama-3.1-405b-instruct (OSS)
`);
        }
        else {
            console.error(`‚ùå Error: Invalid provider "${provider}". Must be "gemini" or "openrouter"`);
            process.exit(1);
        }
        // Keep process running
        process.on('SIGINT', () => {
            console.log('\n\nüëã Shutting down proxy server...');
            process.exit(0);
        });
        // Keep alive
        await new Promise(() => { });
    }
    printProxyHelp() {
        console.log(`
Agentic Flow - Standalone Anthropic Proxy Server

USAGE:
  npx agentic-flow proxy [OPTIONS]

OPTIONS:
  --provider, -p <provider>   Provider (gemini, openrouter) [default: gemini]
  --port, -P <port>           Port number [default: 3000]
  --model, -m <model>         Model to use (provider-specific)
  --help, -h                  Show this help

ENVIRONMENT VARIABLES:
  GOOGLE_GEMINI_API_KEY       Required for Gemini
  OPENROUTER_API_KEY          Required for OpenRouter
  COMPLETION_MODEL            Default model (optional)

EXAMPLES:
  # Start Gemini proxy
  npx agentic-flow proxy --provider gemini --port 3000

  # Start OpenRouter proxy with GPT-4o-mini
  npx agentic-flow proxy --provider openrouter --model "openai/gpt-4o-mini"

  # Use with Claude Code
  export ANTHROPIC_BASE_URL=http://localhost:3000
  export ANTHROPIC_API_KEY=sk-ant-proxy-dummy-key
  claude
`);
    }
    async runQuicProxy() {
        const args = process.argv.slice(3); // Skip 'node', 'cli-proxy.js', 'quic'
        // Parse QUIC arguments
        let port = parseInt(process.env.QUIC_PORT || '4433');
        let certPath = process.env.QUIC_CERT_PATH;
        let keyPath = process.env.QUIC_KEY_PATH;
        for (let i = 0; i < args.length; i++) {
            if ((args[i] === '--port' || args[i] === '-P') && args[i + 1]) {
                port = parseInt(args[++i]);
            }
            else if ((args[i] === '--cert' || args[i] === '-c') && args[i + 1]) {
                certPath = args[++i];
            }
            else if ((args[i] === '--key' || args[i] === '-k') && args[i + 1]) {
                keyPath = args[++i];
            }
            else if (args[i] === '--help' || args[i] === '-h') {
                this.printQuicHelp();
                process.exit(0);
            }
        }
        console.log(`
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë      Agentic Flow - QUIC Transport Proxy Server       ‚ïë
‚ïë           Ultra-Low Latency Agent Communication       ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
`);
        console.log(`üöÄ Starting QUIC Transport Server
üìç Port: ${port}
üîê Protocol: QUIC (UDP-based, TLS 1.3 encrypted)
‚ö° Performance: 50-70% faster than TCP
`);
        if (certPath && keyPath) {
            console.log(`üîí TLS Certificates:
   Cert: ${certPath}
   Key:  ${keyPath}
`);
        }
        else {
            console.log(`‚ö†Ô∏è  Warning: No TLS certificates specified, using development certificates
   Set QUIC_CERT_PATH and QUIC_KEY_PATH for production use
`);
        }
        // Import and start QUIC proxy
        const { spawn } = await import('child_process');
        const { resolve } = await import('path');
        const { fileURLToPath } = await import('url');
        const __filename = fileURLToPath(import.meta.url);
        const __dirname = dirname(__filename);
        const quicProxyPath = resolve(__dirname, './proxy/quic-proxy.js');
        const env = { ...process.env };
        if (certPath)
            env.QUIC_CERT_PATH = certPath;
        if (keyPath)
            env.QUIC_KEY_PATH = keyPath;
        env.QUIC_PORT = port.toString();
        const proc = spawn('node', [quicProxyPath], {
            stdio: 'inherit',
            env: env
        });
        console.log(`‚úÖ QUIC server running on UDP port ${port}!

Features:
  ‚Ä¢ 0-RTT connection establishment
  ‚Ä¢ 100+ concurrent streams per connection
  ‚Ä¢ Built-in TLS 1.3 encryption
  ‚Ä¢ Connection migration support
  ‚Ä¢ Automatic packet loss recovery

Use with agents:
  import { QuicTransport } from 'agentic-flow/transport/quic';
  const transport = new QuicTransport({ port: ${port} });
  await transport.connect();

Press Ctrl+C to stop...
`);
        proc.on('exit', (code) => {
            console.log(`\nüëã QUIC server stopped (exit code: ${code})`);
            process.exit(code || 0);
        });
        process.on('SIGINT', () => {
            console.log('\n\nüëã Shutting down QUIC server...');
            proc.kill('SIGINT');
        });
        process.on('SIGTERM', () => proc.kill('SIGTERM'));
    }
    printQuicHelp() {
        console.log(`
Agentic Flow - QUIC Transport Proxy Server

USAGE:
  npx agentic-flow quic [OPTIONS]

OPTIONS:
  --port, -P <port>           Port number [default: 4433]
  --cert, -c <path>           TLS certificate path
  --key, -k <path>            TLS private key path
  --help, -h                  Show this help

ENVIRONMENT VARIABLES:
  QUIC_PORT                   QUIC server port (default: 4433)
  QUIC_CERT_PATH              Path to TLS certificate
  QUIC_KEY_PATH               Path to TLS private key

EXAMPLES:
  # Start QUIC server (development mode)
  npx agentic-flow quic

  # Start with custom port
  npx agentic-flow quic --port 5443

  # Start with production certificates
  npx agentic-flow quic --cert ./certs/cert.pem --key ./certs/key.pem

  # Use via npm scripts
  npm run proxy:quic         # Start QUIC proxy
  npm run test:quic:wasm     # Test WASM bindings

PROGRAMMATIC USAGE:
  import { QuicTransport } from 'agentic-flow/transport/quic';

  const transport = new QuicTransport({
    host: 'localhost',
    port: 4433,
    maxConcurrentStreams: 100
  });

  await transport.connect();
  await transport.send({ type: 'task', data: { ... } });

PERFORMANCE:
  ‚Ä¢ 50-70% faster than TCP-based protocols
  ‚Ä¢ 0-RTT reconnection (instant resume)
  ‚Ä¢ 100+ concurrent streams per connection
  ‚Ä¢ Built-in TLS 1.3 encryption
  ‚Ä¢ Survives network changes (WiFi ‚Üî cellular)
`);
    }
    async runAgent(options, useOpenRouter, useGemini, useONNX = false, useRequesty = false) {
        const agentName = options.agent || process.env.AGENT || '';
        const task = options.task || process.env.TASK || '';
        if (!agentName) {
            console.error('‚ùå Error: --agent required');
            this.printHelp();
            process.exit(1);
        }
        if (!task) {
            console.error('‚ùå Error: --task required');
            this.printHelp();
            process.exit(1);
        }
        // Set PROVIDER environment variable if --provider flag is used
        if (options.provider) {
            process.env.PROVIDER = options.provider;
        }
        // Check for API key (unless using ONNX)
        const isOnnx = options.provider === 'onnx' || process.env.USE_ONNX === 'true' || process.env.PROVIDER === 'onnx';
        if (!isOnnx && !useOpenRouter && !useGemini && !useRequesty && !process.env.ANTHROPIC_API_KEY) {
            console.error('\n‚ùå Error: ANTHROPIC_API_KEY is required\n');
            console.error('Please set your API key:');
            console.error('  export ANTHROPIC_API_KEY=sk-ant-xxxxx\n');
            console.error('Or use alternative providers:');
            console.error('  --provider openrouter  (requires OPENROUTER_API_KEY)');
            console.error('  --provider gemini      (requires GOOGLE_GEMINI_API_KEY)');
            console.error('  --provider onnx        (free local inference)\n');
            process.exit(1);
        }
        if (!isOnnx && useOpenRouter && !process.env.OPENROUTER_API_KEY) {
            console.error('\n‚ùå Error: OPENROUTER_API_KEY is required for OpenRouter\n');
            console.error('Please set your API key:');
            console.error('  export OPENROUTER_API_KEY=sk-or-v1-xxxxx\n');
            console.error('Or use alternative providers:');
            console.error('  --provider anthropic  (requires ANTHROPIC_API_KEY)');
            console.error('  --provider gemini     (requires GOOGLE_GEMINI_API_KEY)');
            console.error('  --provider onnx       (free local inference)\n');
            process.exit(1);
        }
        if (!isOnnx && useGemini && !process.env.GOOGLE_GEMINI_API_KEY) {
            console.error('\n‚ùå Error: GOOGLE_GEMINI_API_KEY is required for Gemini\n');
            console.error('Please set your API key:');
            console.error('  export GOOGLE_GEMINI_API_KEY=xxxxx\n');
            console.error('Or use alternative providers:');
            console.error('  --provider anthropic   (requires ANTHROPIC_API_KEY)');
            console.error('  --provider openrouter  (requires OPENROUTER_API_KEY)');
            console.error('  --provider onnx        (free local inference)\n');
            process.exit(1);
        }
        const agent = getAgent(agentName);
        if (!agent) {
            const available = listAgents();
            console.error(`\n‚ùå Agent '${agentName}' not found.\n`);
            console.error('Available agents:');
            available.slice(0, 20).forEach(a => {
                console.error(`  ‚Ä¢ ${a.name}: ${a.description.substring(0, 80)}...`);
            });
            if (available.length > 20) {
                console.error(`  ... and ${available.length - 20} more (use --list to see all)`);
            }
            process.exit(1);
        }
        console.log(`\nü§ñ Agent: ${agent.name}`);
        console.log(`üìù Description: ${agent.description}\n`);
        console.log(`üéØ Task: ${task}\n`);
        if (useOpenRouter) {
            const model = options.model || process.env.COMPLETION_MODEL || 'deepseek/deepseek-chat';
            console.log(`üîß Provider: OpenRouter (via proxy)`);
            console.log(`üîß Model: ${model}`);
            // Show tool capability information
            const capabilities = detectModelCapabilities(model);
            if (capabilities.requiresEmulation) {
                console.log(`‚öôÔ∏è  Tool Emulation: ${capabilities.emulationStrategy.toUpperCase()} pattern`);
                console.log(`üìä Note: This model uses prompt-based tool emulation`);
                console.log(`   Tools are handled by Claude Agent SDK (limited to SDK tools)`);
            }
            console.log('');
        }
        else if (useGemini) {
            const model = options.model || 'gemini-2.0-flash-exp';
            console.log(`üîß Provider: Google Gemini`);
            console.log(`üîß Model: ${model}\n`);
        }
        else if (options.provider === 'onnx' || process.env.USE_ONNX === 'true' || process.env.PROVIDER === 'onnx') {
            console.log(`üîß Provider: ONNX Local (Phi-4-mini)`);
            console.log(`üíæ Free local inference - no API costs`);
            if (process.env.ONNX_OPTIMIZED === 'true') {
                console.log(`‚ö° Optimizations: Context pruning, prompt optimization`);
            }
            console.log('');
        }
        console.log('‚è≥ Running...\n');
        // Try Agent Booster pre-processing if enabled
        if (options.agentBooster || process.env.AGENTIC_FLOW_AGENT_BOOSTER === 'true') {
            const preprocessor = new AgentBoosterPreprocessor({
                confidenceThreshold: options.boosterThreshold || parseFloat(process.env.AGENTIC_FLOW_BOOSTER_THRESHOLD || '0.7')
            });
            console.log('‚ö° Agent Booster: Analyzing task for pattern matching opportunities...\n');
            const intent = preprocessor.detectIntent(task);
            if (intent) {
                console.log(`üéØ Detected intent: ${intent.type}`);
                if (intent.filePath) {
                    console.log(`üìÑ Target file: ${intent.filePath}`);
                }
                console.log('üîß Attempting Agent Booster pre-processing...\n');
                const result = await preprocessor.tryApply(intent);
                if (result.success) {
                    console.log(`‚úÖ Agent Booster Success!\n`);
                    console.log(`‚ö° Method: ${result.method}`);
                    console.log(`‚è±Ô∏è  Latency: ${result.latency}ms`);
                    console.log(`üéØ Confidence: ${((result.confidence || 0) * 100).toFixed(1)}%`);
                    console.log(`üìä Strategy: ${result.strategy}`);
                    console.log(`\n‚úÖ File updated successfully!\n`);
                    console.log('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n');
                    console.log(result.output || 'Edit applied');
                    console.log('\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n');
                    logger.info('Agent Booster completed', {
                        agent: agentName,
                        latency: result.latency,
                        confidence: result.confidence,
                        strategy: result.strategy
                    });
                    return; // Skip LLM execution
                }
                else {
                    console.log(`‚ö†Ô∏è  Agent Booster: ${result.reason || 'Low confidence'}`);
                    console.log(`üîÑ Falling back to LLM agent...\n`);
                }
            }
            else {
                console.log('‚ÑπÔ∏è  No code editing pattern detected, using LLM agent...\n');
            }
        }
        const streamHandler = options.stream ? (chunk) => process.stdout.write(chunk) : undefined;
        // Use claudeAgent with Claude Agent SDK - handles multi-provider routing
        const result = await claudeAgent(agent, task, streamHandler);
        if (!options.stream) {
            console.log('\n‚úÖ Completed!\n');
            console.log('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n');
            console.log(result.output);
            console.log('\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n');
        }
        logger.info('Agent completed', {
            agent: agentName,
            outputLength: result.output.length,
            provider: useOpenRouter ? 'openrouter' : useGemini ? 'gemini' : 'anthropic'
        });
    }
    listAgents() {
        const agents = listAgents();
        console.log(`\nüì¶ Available Agents (${agents.length} total)\n`);
        const grouped = new Map();
        agents.forEach(agent => {
            const parts = agent.filePath.split('/');
            const category = parts[parts.length - 2] || 'other';
            if (!grouped.has(category)) {
                grouped.set(category, []);
            }
            grouped.get(category).push(agent);
        });
        Array.from(grouped.entries())
            .sort(([a], [b]) => a.localeCompare(b))
            .forEach(([category, categoryAgents]) => {
            console.log(`\n${category.toUpperCase()}:`);
            categoryAgents.forEach(agent => {
                console.log(`  ${agent.name.padEnd(30)} ${agent.description.substring(0, 80)}`);
            });
        });
        console.log(`\nUsage:`);
        console.log(`  npx agentic-flow --agent <name> --task "Your task"\n`);
    }
    printHelp() {
        console.log(`
ü§ñ Agentic Flow v${VERSION} - AI Agent Orchestration with OpenRouter Support

USAGE:
  npx agentic-flow [COMMAND] [OPTIONS]

COMMANDS:
  config [subcommand]     Manage environment configuration (interactive wizard)
  mcp <command> [server]  Manage MCP servers (start, stop, status, list)
  agent <command>         Agent management (list, create, info, conflicts)
  proxy [options]         Run standalone proxy server for Claude Code/Cursor
  quic [options]          Run QUIC transport proxy for ultra-low latency (50-70% faster)
  claude-code [options]   Spawn Claude Code with auto-configured proxy
  --list, -l              List all available agents
  --agent, -a <name>      Run specific agent mode

CONFIG COMMANDS:
  npx agentic-flow config              # Interactive wizard
  npx agentic-flow config set KEY VAL  # Set configuration value
  npx agentic-flow config get KEY      # Get configuration value
  npx agentic-flow config list         # List all configuration
  npx agentic-flow config delete KEY   # Delete configuration value
  npx agentic-flow config reset        # Reset to defaults

MCP COMMANDS:
  npx agentic-flow mcp start [server]    Start MCP server(s)
  npx agentic-flow mcp stop [server]     Stop MCP server(s)
  npx agentic-flow mcp status [server]   Check MCP server status
  npx agentic-flow mcp list              List all available MCP tools

  Available servers: claude-flow, flow-nexus, agentic-payments, all (default)

AGENT COMMANDS:
  npx agentic-flow agent list [format]   List all agents (summary/detailed/json)
  npx agentic-flow agent create          Create new custom agent (interactive)
  npx agentic-flow agent info <name>     Show detailed agent information
  npx agentic-flow agent conflicts       Check for package/local conflicts

OPTIONS:
  --task, -t <task>           Task description for agent mode
  --model, -m <model>         Model to use (triggers OpenRouter if contains "/")
  --provider, -p <name>       Provider to use (anthropic, openrouter, gemini, onnx)
  --stream, -s                Enable real-time streaming output
  --help, -h                  Show this help message

  API CONFIGURATION:
  --anthropic-key <key>       Override ANTHROPIC_API_KEY environment variable
  --openrouter-key <key>      Override OPENROUTER_API_KEY environment variable
  --gemini-key <key>          Override GOOGLE_GEMINI_API_KEY environment variable

  AGENT BEHAVIOR:
  --temperature <0.0-1.0>     Sampling temperature (creativity control)
  --max-tokens <number>       Maximum tokens in response

  DIRECTORY:
  --agents-dir <path>         Custom agents directory (default: .claude/agents)

  OUTPUT:
  --output <text|json|md>     Output format (text/json/markdown)
  --verbose                   Enable verbose logging for debugging

  EXECUTION:
  --timeout <ms>              Execution timeout in milliseconds
  --retry                     Auto-retry on transient errors

  MODEL OPTIMIZATION (NEW!):
  --optimize, -O              Auto-select best model for agent/task based on priorities
  --priority <type>           Optimization priority:
                              ‚Ä¢ quality   - Best results (Claude Sonnet 4.5, GPT-4o)
                              ‚Ä¢ balanced  - Mix quality/cost (DeepSeek R1, Gemini 2.5 Flash) [default]
                              ‚Ä¢ cost      - Cheapest (DeepSeek Chat V3, Llama 3.1 8B)
                              ‚Ä¢ speed     - Fastest responses (Gemini 2.5 Flash)
                              ‚Ä¢ privacy   - Local only (ONNX Phi-4, no cloud)
  --max-cost <dollars>        Maximum cost per task (e.g., 0.001 = $0.001/task budget cap)

  Optimization analyzes agent type + task complexity to recommend best model.
  Example savings: DeepSeek R1 costs 85% less than Claude Sonnet 4.5 with similar quality.
  See docs/agentic-flow/benchmarks/MODEL_CAPABILITIES.md for full comparison.

EXAMPLES:
  # MCP Server Management
  npx agentic-flow mcp start              # Start all MCP servers
  npx agentic-flow mcp start claude-flow  # Start specific server
  npx agentic-flow mcp list               # List all 203+ MCP tools
  npx agentic-flow mcp status             # Check server status

  # Proxy Server for Claude Code/Cursor
  npx agentic-flow proxy --provider openrouter --port 3000
  npx agentic-flow proxy --provider gemini --port 3001

  # QUIC Transport (Ultra-low latency, 50-70% faster than TCP)
  npx agentic-flow quic --port 4433                    # Start QUIC server
  npx agentic-flow quic --cert ./certs/cert.pem --key ./certs/key.pem
  npm run proxy:quic                                    # Development mode
  npm run test:quic:wasm                                # Test WASM bindings

  # Claude Code Integration (Auto-start proxy + spawn Claude Code)
  npx agentic-flow claude-code --provider openrouter "Write a Python function"
  npx agentic-flow claude-code --provider gemini "Create a REST API"
  npx agentic-flow claude-code --provider anthropic "Help me debug this code"

  # Agent Execution
  npx agentic-flow --list                 # List all 150+ agents
  npx agentic-flow --agent coder --task "Create Python hello world"
  npx agentic-flow --agent coder --task "Create REST API" --provider openrouter
  npx agentic-flow --agent coder --task "Create REST API" --model "meta-llama/llama-3.1-8b-instruct"
  npx agentic-flow --agent coder --task "Create code" --provider onnx

  # Model Optimization (Auto-select best model)
  npx agentic-flow --agent coder --task "Build API" --optimize
  npx agentic-flow --agent coder --task "Build API" --optimize --priority cost
  npx agentic-flow --agent reviewer --task "Security audit" --optimize --priority quality
  npx agentic-flow --agent coder --task "Simple function" --optimize --max-cost 0.001

ENVIRONMENT VARIABLES:
  ANTHROPIC_API_KEY       Anthropic API key (for Claude models)
  OPENROUTER_API_KEY      OpenRouter API key (for alternative models)
  GOOGLE_GEMINI_API_KEY   Google Gemini API key (for Gemini models)
  USE_OPENROUTER          Set to 'true' to force OpenRouter usage
  USE_GEMINI              Set to 'true' to force Gemini usage
  COMPLETION_MODEL        Default model for OpenRouter
  AGENTS_DIR              Path to agents directory
  PROXY_PORT              Proxy server port (default: 3000)
  QUIC_PORT               QUIC transport port (default: 4433)
  QUIC_CERT_PATH          Path to TLS certificate for QUIC
  QUIC_KEY_PATH           Path to TLS private key for QUIC

OPENROUTER MODELS (Best Free Tested):
  ‚úÖ deepseek/deepseek-r1-0528:free           (reasoning, 95s/task, RFC validation)
  ‚úÖ deepseek/deepseek-chat-v3.1:free         (coding, 21-103s/task, enterprise-grade)
  ‚úÖ meta-llama/llama-3.3-8b-instruct:free    (versatile, 4.4s/task, fast coding)
  ‚úÖ openai/gpt-4-turbo                       (premium, 10.7s/task, no :free needed)

  All models above support OpenRouter leaderboard tracking via HTTP-Referer headers.
  See https://openrouter.ai/models for full model catalog.

MCP TOOLS (213+ available):
  ‚Ä¢ agentic-flow: 7 tools (agent execution, creation, management, model optimization)
  ‚Ä¢ claude-flow: 101 tools (neural networks, GitHub, workflows, DAA)
  ‚Ä¢ flow-nexus: 96 cloud tools (sandboxes, distributed swarms, templates)
  ‚Ä¢ agentic-payments: 6 tools (payment authorization, multi-agent consensus)

OPTIMIZATION BENEFITS:
  üí∞ Cost Savings: 85-98% cheaper models for same quality tasks
  üéØ Smart Selection: Agent-aware (coder needs quality ‚â•85, researcher flexible)
  üìä 10+ Models: Claude, GPT-4o, Gemini, DeepSeek, Llama, ONNX local
  ‚ö° Zero Overhead: <5ms decision time, no API calls during optimization

PROXY MODE (Claude Code CLI Integration):
  The OpenRouter proxy allows Claude Code to use alternative models via API translation.

  Terminal 1 - Start Proxy Server:
    npx agentic-flow proxy
    # Or with custom port: PROXY_PORT=8080 npx agentic-flow proxy
    # Proxy runs at http://localhost:3000 by default

  Terminal 2 - Use with Claude Code:
    export ANTHROPIC_BASE_URL="http://localhost:3000"
    export ANTHROPIC_API_KEY="sk-ant-proxy-dummy-key"
    export OPENROUTER_API_KEY="sk-or-v1-xxxxx"

    # Now Claude Code will route through OpenRouter proxy
    claude-code --agent coder --task "Create API"

  Proxy automatically translates Anthropic API calls to OpenRouter format.
  Model override happens automatically: Claude requests ‚Üí OpenRouter models.

  Benefits for Claude Code users:
  ‚Ä¢ 85-99% cost savings vs Claude Sonnet 4.5
  ‚Ä¢ Access to 100+ models (DeepSeek, Llama, Gemini, etc.)
  ‚Ä¢ Leaderboard tracking on OpenRouter
  ‚Ä¢ No code changes to Claude Code itself

QUIC TRANSPORT (Ultra-Low Latency Agent Communication):
  QUIC is a UDP-based protocol offering 50-70% faster connections than TCP.

  Performance Benefits:
  ‚Ä¢ 0-RTT connection establishment - Instant reconnection without handshake delay
  ‚Ä¢ Stream multiplexing - Send 100+ concurrent messages without blocking
  ‚Ä¢ Built-in TLS 1.3 security - Encrypted by default
  ‚Ä¢ Connection migration - Survives network changes (WiFi ‚Üí cellular)
  ‚Ä¢ Reduced latency - Perfect for real-time agent coordination

  Programmatic Usage (API):
    import { QuicTransport } from 'agentic-flow/transport/quic';

    const transport = new QuicTransport({
      host: 'localhost',
      port: 4433,
      maxConcurrentStreams: 100
    });

    await transport.connect();
    await transport.send({ type: 'task', data: { ... } });

  CLI Usage:
    # Start QUIC server
    npx agentic-flow quic --port 4433

    # With custom certificates
    npx agentic-flow quic --cert ./certs/cert.pem --key ./certs/key.pem

    # Test WASM bindings
    npm run test:quic:wasm

    # Development mode
    npm run proxy:quic:dev

  Use Cases:
  ‚Ä¢ Multi-agent swarm coordination (mesh/hierarchical topologies)
  ‚Ä¢ High-frequency task distribution across worker agents
  ‚Ä¢ Real-time state synchronization between agents
  ‚Ä¢ Low-latency RPC for distributed agent systems

DOCUMENTATION:
  https://github.com/ruvnet/agentic-flow
  https://ruv.io
    `);
    }
}
// Run CLI
const cli = new AgenticFlowCLI();
cli.start();
