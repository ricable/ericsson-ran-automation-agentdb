---
complexity_score: 29.5
converted_at: '2025-08-13T06:56:42.153686Z'
file_type: html
format: html
image_processing_enhanced: true
images_extracted: 39
images_saved: 3
original_path: 324_22112-IPM10141_100Uen.AU.html
pictures_extracted: 39
processing_method: docling_multimodal
quality_score: 9.0
source_file: 324_22112-IPM10141_100Uen.AU.html
source_zip: en_lzn7931071_r38f.zip
tables_extracted: 8
zip_image_types:
- .svg
- .png
- .gif
- .jpg
- .bmp
zip_images_total: 2796
---

# 

E2E QoS Guideline

Contents

![Image](../images/324_22112-IPM10141_100Uen.AU/additional_3_CP.png)

![Image](../images/324_22112-IPM10141_100Uen.AU/additional_3_CP.png)

|   1 | Introduction                          |
|-----|---------------------------------------|
| 1.1 | General                               |
| 1.2 | Scope                                 |
| 2   | Principles and Guidelines             |
| 2.1 | Common Support Services QoS           |
| 2.2 | LTE QoS Handling                      |
| 2.3 | NR QoS Handling                       |
| 2.4 | QoS Mapping for the Transport Network |
| 2.5 | Rate Adaptation by L4S                |
| 3   | Transport Network QoS Aspects         |
| 3.1 | Packet Classification and Marking     |
| 3.2 | Bandwidth Control                     |
| 3.3 | Queuing and Scheduling                |
| 3.4 | Congestion Avoidance                  |
| 4   | Solution Guideline Change History     |

# 1 Introduction

This document aims to support solution architects in the network planning phase to address Quality of Service (QoS) design-related issues from an E2E perspective.

Implementing E2E QoS is necessary to meet the different requirements and to ensure the high Quality of Experience (QoE) for end users.

The bandwidth demands for RAN have increased dramatically because of the rise of applications, such as Video on Demand and social media applications.

5G network needs service differentiation for different use cases, such as eMBB, FWA, and TCC, which require different QoS settings.

Most mobile operators have common backhaul network infrastructures carrying 2G, 3G, 4G, and 5G services. All of these services have unique traffic handling and QoS requirements in terms of delay, delay variation (jitter), packet loss, and bit error rate.

## 1.1 General

The mobile network handles various traffic types, including delay-sensitive traffic, such as voice, high-quality video, and data. Each traffic type has different requirements that must be addressed by the RAN, the transport network, and the core networks.

For example, high throughput data traffic can share the network simultaneously with delay-sensitive real-time traffic. QoS ensures that the traffic characteristics of each type are fulfilled. This can be achieved by, for example, giving the delay-sensitive traffic a higher priority with less E2E delay and jitter values and a lower guaranteed minimum throughput. In this case, the more flexible (elastic) traffic type can be given a lower priority, with higher E2E delay and jitter values, but more bandwidth when available.

The figure below shows the overall user experience designed for QoS guidelines in the NR RAN library. This document describes QoS mechanisms to support the service differentiations, including the 3GPP QoS framework, Ericsson proprietary scheduling algorithms, and high-level realizations between 3GPP framework and use cases.

![Image](../images/324_22112-IPM10141_100Uen.AU/additional_3_CP.png)

Figure 1   User Experience Design for QoS Guidelines in NR RAN Library

For low-level realizations between 3GPP QoS Framework and use cases, see the following dedicated solution guidelines:

- 5G Voice SA RAN Solution Guideline
- NR SA Network Slicing Guideline
- NR Fixed Wireless Access Solution Guideline
- Solution Guideline for Real-Time Media Services in Public RAN

## 1.2 Scope

This document provides E2E QoS design guidelines to develop an example E2E QoS framework. It covers different RAT types using a common backhaul. The following items are within the scope of this document:

- Describing traffic manager concepts
- Summary and explanation of existing QoS implementations for LTE and NR
- LTE QoS Handling
- NR QoS Handling
- Mapping radio and core traffic QoS data to the Differentiated Services Code Point (DSCP) and the Ethernet Priority Bits (P-Bits)

The following items are outside the scope of this document:

- Hierarchical QoS
- Detailed QoS node configurations and limitations
- WCDMA &amp; GSM QoS requirements for the Circuit Switched part
- For slice-based QoS differentiation, see the NR SA Network Slicing Guideline.

# 2 Principles and Guidelines

An E2E QoS implementation enables operators to create differentiation in their networks, both between subscribers and services. It also allows them to allocate and supply adequate network resources based on subscriber and service requirements.

QoS handling is enforced as follows:

- With QoS flows from an E2E perspective
- With the QoS transport traffic management on a single enforcement point, such as a transport node

QoS handling in WCDMA, LTE, and NR is the result of the QoS negotiation between the UE, the RAN, and the packet core network. It defines the end user experience of the different services in both non-congested and congested networks.

From an E2E perspective, QoS can be enforced in a static or dynamic manner.

The static subscriber QoS is configured in the Home Subscriber Server (HSS) or Home Location Register (HLR). It can be configured through a predefined QoS profile in the Serving GPRS Support Node (SGSN) and Mobility Management Entity (MME).

Dynamic QoS means that the Policy and Charging Rules Function (PCRF) or the Service-Aware Policy Controller (SAPC) evaluates the QoS. Its evaluation depends on the service, session, location, and subscriber parameters, and different trigger conditions.

Radio bearer traffic is mapped to the DSCP, which enables the intermediate transport network to prioritize traffic. In transport networks with limited capacity, it is important that the mapping is done at the egress ports of the related RAN and core nodes. A DSCP value defines a Per-Hop Behavior (PHB), that is, a set of packet forwarding properties given to an IP packet transported through the network.

The E2E QoS design uses a blend of the 3GPP and IETF QoS architectures.

3GPP QoS Architecture

ETSI and 3GPP define a QoS architecture for WCDMA, LTE, and NR-based mobile networks.

The 3GPP mechanisms define the QoS flow concept. The QoS flow is carried over the air interface on a data radio bearer. Between NG-RAN and 5G core network, it is tunneled and reaches the external peer entity as external flow. A bearer is responsible for tunneling end user data between mobile terminals and the core network. The QoS flow Identifier identifies the traffic type based on end user subscription details or core network enforcement policies.

Bearers are categorized as Signaling Radio Bearers (SRBs) or Data Radio Bearers (DRBs).

IETF QoS Architecture

The IETF DiffServ model describes the transport QoS aspects. It offers a simple and coarse method of providing Differentiated Service classes for different application types.

The DiffServ architecture is composed of the following functional elements implemented in network nodes:

- Per-Hop Behaviors (PHBs)
- Traffic classification functions
- Traffic conditioning functions, such as metering, marking, shaping, and dropping

The scalability is achieved by implementing classification and conditioning functions at network boundary nodes and by applying PHBs to aggregates of traffic. The aggregates are first marked using specific fields in the IP (DSCP), TC (MPLS), or P-Bit (Ethernet) headers.

The figure below shows the mapping of 3GPP QoS flows to IETF transport QoS DiffServ classes.

![Image](../images/324_22112-IPM10141_100Uen.AU/additional_3_CP.png)

Figure 2   3GPP QoS to DiffServ Mapping Overview

Note:  Mapping from DiffServ to MPLS or P-Bits, or the other way around, is a function of the IETF QoS principles. 3GPP only defines mapping bearer-level QoS to IETF DSCP transport QoS.

## 2.1 Common Support Services QoS

In this section, non-radio control plane traffic refers to the following services:

- Signaling
- Operation and Maintenance (O&amp;M)
- Synchronization
- Transport network routing and switching protocols

Control plane traffic is locally generated traffic from multiple nodes in the RAN, transport, and core domains. The traffic is directly mapped to one of the DSCP and P-Bit values by the node that initiates the traffic. The value depends on the type of traffic and the node capability.

Depending on the node type and software release, some nodes allow the default DSCP and P-Bit values to be changed. On other nodes, the values are hard-coded.

| Application or Service    | Traffic Example                                                                                                                                                                                          | PHB       |   DSCP |
|---------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------|--------|
| Synchronization           | Network frequency or time and phase synchronization                                                                                                                                                      | Local Use |     54 |
| Transport Network Control | IP Routing (BGP, OSPF, IS-IS), NTP, ToD, L2 resilience, ICMP, DHCP, and so on; ICMP including pings and ICMP traceroute, RIP, SNTP, Secure HTTP, and SNMP                                                | CS6       |     48 |
| Signaling                 | Core Network control (MAP, SIP-I, GTP-C, GTP, DIAMETER, RADIUS, DNS for APN resolution and MSS, LDAP, and so on); Application signaling (SIP, H.248, and so on)                                          | CS5       |     40 |
| O&M High Priority         | O&M configuration management; SNMP traps (alarms)                                                                                                                                                        | CS4       |     32 |
| O&M Undifferentiated      | O&M high and low priority, if separation is not possible                                                                                                                                                 | CS2       |     16 |
| O&M Low Priority          | O&M Interactive, O&M Bulk, CUDB replication, charging low priority (FTP), SIU O&M; Low-Priority OAM: Secure remote login (SSH), secure software download, logs upload (SFTP), and data collection upload | CS1       |      8 |

## 2.2 LTE QoS Handling

LTE E2E QoS aspects are briefly described in these sections. For more details, see the QoS configuration user guides by node type.

### 2.2.1 LTE QoS Model Overview

#### 2.2.1.1 EPS Bearer Model

LTE QoS handling follows the QoS concept defined in 3GPP TS 23.203.

A bearer is a traffic separation element that enables differentiated treatment of traffic based on the QoS requirements. It provides a logical path between the UE and a Packet Data Network Gateway (PDN-GW). All flows mapped to a single bearer receive the same packet forwarding treatment between the UE and the gateway. This includes scheduling, queue management, and rate shaping.

The figure below shows the bearer model.

![Image](../images/324_22112-IPM10141_100Uen.AU/additional_3_CP.png)

Figure 3   LTE Bearer Model

An Evolved Packet System (EPS) bearer has the following elements:

- A radio bearer transports the packets of an EPS bearer between a UE and an eNodeB.
- An S1 bearer transports the packets of an EPS bearer between an eNodeB and a serving gateway.
- An E-UTRAN Radio Access Bearer (E-RAB) refers to the concatenation of an S1 bearer and the corresponding radio bearer.
- An S5 or S8 bearer transports the packets of an EPS bearer between a Serving Gateway (SGW) and a PGW.

An EPS bearer is classified as a default or a dedicated bearer based on its QoS requirements. When a mobile device first attaches to an LTE network, it is assigned a default bearer. The default bearer is associated with the IP address of the UE. It does not have a bit rate guarantee and offers only best-effort service. A dedicated bearer acts as another bearer beside the default. It provides a dedicated tunnel to give appropriate treatment to specific services.

A dedicated bearer is further classified as a Guaranteed Bit Rate (GBR) bearer or a non-GBR bearer. GBR has dedicated network resources and is required for time-sensitive traffic, for example real-time voice and video applications.

#### 2.2.1.2 Service Data Flows (SDF)

The figure below shows Service Data Flows (SDFs) and their relation to the EPS bearers.

![Image](../images/324_22112-IPM10141_100Uen.AU/additional_3_CP.png)

Figure 4   SDFs and EPS Bearers

In an LTE network, user traffic (IP flows or IP packets) is classified into SDF traffic and EPS bearer traffic. An SDF refers to a group of IP flows associated with a user service. An EPS bearer refers to IP flows of aggregated SDFs that have the same QoS class.

The SDF and the EPS bearer are identified by matching the IP flows to the packet filters at the UEs and the PGW. The filters used are SDF filters for SDFs and Traffic Flow Templates (TFTs) for EPS bearers. The filters are preconfigured by network operators in accordance with their policy. Each filter typically consists of the following:

- Source IP address
- Destination IP address
- Source port number
- Destination port number
- Protocol ID

In an LTE network, IP flows with service characteristics that match the SDF template packet filter are designated to an SDF. SDFs that match the packet filters of the TFT are mapped to an EPS bearer, to be then delivered to a UE. SDFs with the same QoS class are delivered aggregated through an EPS bearer. SDFs with different QoS classes are delivered through different EPS bearers.

#### 2.2.1.3 LTE QoS Parameters

In an LTE network, QoS parameters are defined on the following levels:

- Service level: SDF QoS parameters
- Bearer level: EPS bearer QoS parameters

QoS Class Identifier (QCI) and ARP are basic QoS parameters applied to all SDFs and EPS bearers. The QCI is important, because it is a reference that indicates the performance characteristics of SDFs and EPS bearers. SDFs and EPS bearers are then mapped to certain PHBs in the transport network.

An SDF aggregate is a group of SDFs which have the same QCI and ARP values. They belong to one EPS session, that is, one PDN connection.

The figure below shows the additional QoS parameters that are used.

Figure 5   Additional QoS Parameters

The figure below summarizes the main LTE QoS parameters, related both to SDF and EPS bearers.

Figure 6   LTE QoS Parameters

QoS parameters for EPS bearers are enforced in EPS entities (UE, eNodeB, SGW, PGW) that deliver user traffic between the UE and the PGW. The table below shows which QoS parameter is enforced to which EPS entity.

| EPS Bearer QoS Parameter   | Enforcement                                                                                                                                              |
|----------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------|
| QCI                        | Applied to all bearers by all entities (UE, eNodeB, SGW, and PGW).                                                                                       |
| ARP                        | Applied to all bearers by the eNodeB, the SGW, and the PGW.                                                                                              |
| MBR                        | Applied to GBR bearers only. For UL, it is applied to GBR bearers by the UE and the eNodeB; For DL, it is applied to GBR bearers by the SGW and the PGW. |
| GBR                        | Applied to GBR bearers only by the eNodeB, the SGW, and the PGW.                                                                                         |
| APN-AMBR                   | Applied to non-GBR bearers only. For UL, it is applied to non-GBR bearers by the UE and the PGW; For DL, it is applied to non-GBR bearers by the PGW.    |
| UE-AMBR                    | Applied to non-GBR bearers in UL if configured using End User bit rate Shaping. (Not supported for DL.)                                                  |

The figure below shows a high-level overview of the roles of the main QoS nodes. For more information, see the CPI documentation of the appropriate node.

![Image](../images/324_22112-IPM10141_100Uen.AU/additional_3_CP.png)

Figure 7   Overview of E2E EPS Node QoS Roles

### 2.2.2 QoS Mapping of EPS Bearers to Transport (QCI to DSCP
      Mapping)

The EPS user plane traffic is transported over the S1 interface through E-RABs. Each E-RAB has a QCI assigned to it when it is set up with S1AP signaling. The QCI defines QoS characteristics for data transported over the E-RAB.

In an LTE network, the eNodeB and the SGW map QCI to DSCP and P-Bit values. The operator can configure the mapping on these nodes for each QCI value.

For the E-RAB nodes, it is recommended to configure the QCI to DSCP mapping as defined in  Recommended Mappings of 5QI and QCI to DSCP and in  QoS Mapping for the Transport Network. The S1AP and X2AP messages that are transported over the SCTP protocol, which is encapsulated in IP packets, are mapped to DSCP 40, see  QoS Mapping for the Transport Network.

For other types of non-radio signaling and control traffic, see  Common Support Services QoS.

Related concepts

QoS Mapping for the Transport Network

#### 2.2.2.1 QoS Mapping with the Feature DSCP Mapping Based on ARP
        and QCI

When the feature "DSCP Mapping Based on ARP and QCI" is active, the eNodeB maps QCI values to Transport DSCP values depending on the ARP value. This enables the operator to classify priority services differently if the services share the same QCI value with other services but have different ARP value.

![Image](../images/324_22112-IPM10141_100Uen.AU/additional_3_CP.png)

Figure 8   Example of DSCP Mapping Based on ARP and QCI with the Feature "DSCP Mapping Based on ARP and QCI"

### 2.2.3 Scheduling for LTE

This section focuses on the QoS aspects for an LTE deployment case.

For the Downlink (DL) traffic, the eNodeB schedules the traffic for the DRB with the scheduler and the priorities that are defined for the DRB.

For the Uplink (UL) traffic the eNodeB schedules this traffic per Logical Channel Group (LCG) with the scheduler and the priorities that are defined for the LCG. The LCG inherits scheduling capabilities, for example, the absolute priority (absolute priority override), the scheduler, the relative priority (if applicable), from the radio bearers in the LCG. This means that in the UL direction all radio bearers in an LCG are scheduled in the same way. The LCG is valid per UE.

If service differentiation for different radio bearers in the UL traffic is important, then the QCIs need to be assigned to different LCGs.

The following sections introduce a brief description of the most important schedulers for LTE.

#### 2.2.3.1 QoS-Aware Scheduler

The QoS-Aware Scheduler feature enables the eNodeB to perform Absolute Priority Scheduling for Data Radio Bearers (DRBs) on a QCI basis. It also enables configuration of scheduling algorithms per QCI, given that appropriate scheduler licenses are in place.

The eNodeB's QoS-Aware Scheduler function is an Absolute Priority Scheduling function, that schedules LTE radio bearers with a higher absolute priority before bearers with a lower absolute priority.

If service differentiation for different radio bearers in the UL traffic is important, then the operator needs to define the LCGs so that relevant Priority Levels are mapped to different LCGs.

For more information on the feature description, see QoS-Aware Scheduler.

#### 2.2.3.2 Minimum Rate Proportional Fair Scheduler

The Minimum Rate Proportional Fair Scheduler feature enables the eNodeB to schedule the traffic. It ensures a balance between high cell throughput and fair throughput for subscribers with poor radio conditions.

By prioritizing users experiencing good channel quality, a higher throughput can be achieved. However, to avoid that some users are scheduled with too few or no resources because of poor channel quality, fairness is provided by also considering the average rate in the scheduler prioritization.

As a prerequisite the feature 'QoS-Aware Scheduler' must be activated and configured.

For more information on the feature description, see Minimum Rate Proportional Fair Scheduler.

#### 2.2.3.3 Relative Priority Scheduling

The Relative Priority Scheduling feature allows the operator to control the bit rate proportions. The services are assigned the proportions through a specific QCI parameter in relation to other services using other QCIs. The Relative Priority Scheduling feature provides the specified bit rate ratios when either the radio conditions are ignored (equal rate), or when all UEs have similar radio conditions. Otherwise, the difference in experienced radio conditions influences the resulting bit rate proportions (proportional fair).

As a prerequisite the features QoS-Aware Scheduler and Minimum Rate Proportional Fair Scheduler must be activated and configured.

If the service differentiation for different radio bearers in the uplink traffic is important, then the operator needs to define the LCGs so that the affected Relative Priority Levels are the best possible.

For more information on the feature description, see Relative Priority Scheduling.

## 2.3 NR QoS Handling

### 2.3.1 General Overview

#### 2.3.1.1 NR SA Option 2 QoS Model Overview

In this document, NR standalone (SA) refers to an NR deployment with Option 2. It defines a different network architecture from the LTE. NR non-standalone (NSA) refers to an NR NSA deployment with Option 3x.

This section describes the main components of the NR QoS framework with the main focus on how to treat the relevant QoS parameters for NR.

The figure below shows a general 5G QoS model overview. In further subsections details are provided for the 5G QoS framework, QoS flow mapping, 5G QoS parameters, 5QI, QoS mapping to transport and scheduling in NR.

![Image](../images/324_22112-IPM10141_100Uen.AU/additional_3_CP.png)

Figure 9   A 5G QoS Model Overview

The 5G QoS model is flow-based, unlike the bearer-based LTE QoS model. This is represented in the following ways:

- In the figure above, the E2E services refer to the network or application services between a UE and the external Data Network, for example, the Internet. Different E2E services require differentiated QoS treatments.
- Each E2E service can have one or multiple IP flows. An SDF is one IP flow or an aggregation of IP flows of a UE traffic classified by the type of the service that is used.
- One or more SDFs can be transported in the same 5G QoS flow if they share the same QoS treatment.
- Each uplink and downlink packet are mapped to a QoS flow. This QoS flow provides an E2E forwarding treatment between the UE and the UPF throughout the lifetime of the PDU session.
- One PDU session can carry one or several QoS flows, where all QoS flows of a certain PDU session are sent over the same NG-U tunnel.
- The QoS Flow ID (QFI) identifies a QoS flow in a PDU session. The user plane traffic with the same QFI within a PDU session receives the same traffic forwarding treatment, for example, scheduling or admission threshold.
- Each PDU session is allocated to a unique QFI. Each QoS flow is characterized by a set of parameters that are defined in a QoS profile, for example, 5G QoS Identifier (5QI), ARP, or Guaranteed Flow Bit Rate (GFBR).
- A radio bearer can carry one or several QoS flows. Each PDU session has a unique set of radio bearers and the gNodeB decides over which radio bearer a QoS flow is sent.

Note:  In the current release, the gNodeB only supports one QoS flow per DRB.

The QoS resources related to scheduling or flow control in RAN are always configured per 5QI and can be customized in a slice-specific way. For the slicing specifics, see NR SA Network Slicing Guideline.

The PCF is a key element in the process of E2E QoS enforcement. It controls QoS both at PDU session level and SDF level:

- At the PDU session level, it ensures that the authorized Default QoS and Session AMBR assigned to the PDU session is in accordance with the operator's requirements.
- At the SDF level, it ensures that each service packet flow is handled with the right QoS parameters, using preconfigured, static, or dynamic PCC rules.

When the PCF sends a PCC Rule to the SMF through N7 with QoS information (for example, 5QI, ARP, MFBR/GFBR), the SMF performs the binding of SDFs to QoS Flows, and it evaluates the possibility to either use one of the existing QoS Flows, initiate QoS Flows modification or even trigger the establishment of a new QoS Flow.

The SMF then formulates different QoS constructs, and sends it to each enforcement entity along the QoS Flow as follows:

- "SDF Template" to UPF, over N4
- "QoS Profile" to gNB, through AMF, over NG-C
- "QoS Rule" to UE, through AMF and gNB, over N1

"QoS Rules" and "SDF Templates" apply Packet Filter Sets (PFS) to classify and map the user plane traffic to a certain QoS Flow. The PFS can contain packet filters for the downlink direction, the uplink direction, or both.

Note:  "SDF Template", "QoS Profile" and "QoS Rules" contain the same QFI identifier that represents the QoS characteristic of the QoS Flow.

The figure below shows the 5G QoS framework.

![Image](../images/324_22112-IPM10141_100Uen.AU/additional_3_CP.png)

Figure 10   The 5G QoS Framework

The dynamic modification of the already established QoS properties in NR SA, NR-DC, and EN-DC, provides increased flexibility when changing the characteristics of the service provided for individual UEs, see section  NR Dynamic QoS Modification.

The following messages are used to provide QoS rules, QoS profiles, and SDF templates respectively, depending on the establishment or the modification of the PDU Session:

N1:

- PDU SESSION ESTABLISHMENT ACCEPT
- PDU SESSION MODIFICATION COMMAND

NG-C:

- PDU SESSION RESOURCE SETUP REQUEST
- PDU SESSION RESOURCE MODIFY REQUEST

N4:

- N4 SESSION ESTABLISHMENT REQUEST
- N4 SESSION MODIFICATION REQUEST

The QoS characteristics of 3GPP standardized 5QIs can be conveyed to the RAN in the following ways:

- gNodeB: The QoS characteristics for standardized 5QIs can be pre-defined in the RAN through MOM configuration, either using a default or slice-specific QoS setup. The certain QoS characteristics can also be configured differently for each UE group by using the UE Grouping Framework.
- Core Network (5GC) Signaling: The certain QoS characteristics, such as the default priority level configured in 5GC functions including the Unified Data Management (UDM) and Policy Control Function (PCF), are signaled to the RAN in the PDU SESSION RESOURCE SETUP or MODIFY REQUEST messages.

In case the RAN receives QoS characteristics input from multiple sources, the corresponding attribute values determined through UE group evaluation take precedence over the 5GC signaled values. The 5GC signaled values, in turn, take precedence over the normal MOM-configured values.

The figure below shows the 5GC signaling case where the DNN used by the PDU Session of the UE is associated with a priority level for the default QoS flow using 5QI 9, which is differently pre-configured in the RAN and is overwritten by the 5GC signaling.

Note:  The subscribed QoS Profile information for the default QoS flow in a PDU session is specified as part of the Data Network Name (DNN) configuration in UDM. This information includes, for example, the 5QI, the priority level and ARP.

![Image](../images/324_22112-IPM10141_100Uen.AU/additional_3_CP.png)

Figure 11   Signaling of QoS Characteristics from 5GC to RAN

The figure above shows the signaling of QoS characteristics from 5GC to RAN when UE1 associated with slice 1 sets up the PDU session for DNN 1. Then, the SMF retrieves the subscribed QoS Profile information from the UDM or the PCF. This information includes the modified 5QI 9 priority level. The SMF forwards the retrieved information to the AMF. The AMF transparently transfers this as part of the QoS Flow Level QoS Parameters information element in PDU SESSION RESOURCE SETUP messages to the RAN, where the 5GC signaled priority level overrides the gNodeB configured priority level in the bearer context of the corresponding UEs. This only works for standardized or pre-configured 5QIs using the non-dynamic 5QI information element in QoS Flow Level QoS Parameters. The Dynamic 5QI information element is not supported by the gNodeB.

#### 2.3.1.2 NR NSA Option 3x QoS Model Overview (EN-DC)

The LTE-NR Dual Connectivity, for example, E-UTRA-NR Dual Connectivity (EN-DC) RAN, is introduced with NR NSA Option 3x. Here a supporting UE is simultaneously associated with LTE (eNodeB) and NR (gNodeB). For a detailed description of Option 3x connectivity, see NR NSA Connectivity Guideline with Option 3x.

The LTE EPS bearer QoS framework defined in TS 36.300 applies for NR NSA Option 3x as well.

In the EN-DC architecture, the control plane and user plane traffic are defined as follows:

Control Plane Traffic

The eNodeB serves as the UE anchor point and handles related signaling traffic for both LTE and NR services. The eNodeB acts as the RAN master node towards the gNodeB over an X2-C interface. The eNodeB communicates with the MME over the S1-C interface.

User Plane Traffic

The user Data Radio Bearer (DRB) is set up either as a split-bearer (using both LTE and NR radio resources) or as an LTE-only bearer (using only LTE radio resources).

A split bearer is a 3GPP function related to Dual Connectivity to enable the division of a bearer between LTE and NR for optimized session performance. With the split DRBs, the traffic behaves as follows:

Uplink User Plane Traffic

The uplink user plane traffic is configurable and controlled by the operator. The traffic is handled by the MCG radio resources only (default) or by the SCG radio resources only, or over both RAT types.

Downlink User Plane Traffic

The downlink user plane traffic can be sent over either the NR or the LTE RAT or sent simultaneously over both RAT types.

From a QoS perspective, the QCI and ARP values define if a bearer can be moved in split-bearer mode by the gNodeB.

Under certain conditions, the X2 link in the new 5G EN-DC architecture can carry the peak LTE RAT capacity of the connected master eNodeB for data traffic only.

For the EN-DC case, the VoLTE Voice traffic is carried over LTE DRBs if the UE is in split-bearer configuration and the gNodeB decides to use only LTE resources in the downlink. Therefore, the QoS implementation on the X2 links is vital for an EN-DC RAN.

The figure below shows the conceptual architecture for the EPS with EN-DC. For the LTE-NR Dual Connectivity with NR NSA option 3x, the supporting UE is connected to LTE (eNodeB) and NR (gNodeB), which means that a scheduler in eNodeB and a scheduler in gNodeB schedule traffic on the DRBs to the connected UE. The eNodeB schedules the MN terminated MCG and the SN terminated split DRB (MCG) traffic for the connected UE. The gNodeB schedules the traffic for the SN terminated split DRB (SCG) with the NR scheduler functions and the priorities that are defined for the DRB.

![Image](../images/324_22112-IPM10141_100Uen.AU/additional_3_CP.png)

Figure 12   Conceptual Architecture for EPS with EN-DC (Option 3x)

#### 2.3.1.3 QoS Profile

The QoS profile of the QoS flow defines whether the QoS flow is GBR or non-GBR. The QoS profile is configured in the gNodeB and is characterized by 5G QoS parameters.

#### 2.3.1.4 QoS Rules and SDF Templates

The QoS rules are configured in the UEs and the SDF templates are configured on the UPFs. They apply packet filter sets to classify and map the user plane traffic to a QoS flow. The packet filter sets can contain packet filters for the downlink direction, the uplink direction, or both.

#### 2.3.1.5 QoS Flow Mapping

The figure below shows a general view of the user plane QoS flow mapping.

![Image](../images/324_22112-IPM10141_100Uen.AU/additional_3_CP.png)

Figure 13   A User Plane QoS Flow Mapping

Note:  Only one QoS Flow per Radio Bearer (DRB) is implemented.

In the uplink direction, the QoS flow-mapping process is as follows:

1. For a PDU session initiated between a UE and the UPF, the UE maps the uplink user plane traffic to a QoS flow, which is identified by a unique QFI value within the PDU session. This mapping is done based on matching uplink packets against the uplink packet filters in the QoS rules configured in the UE.

- If no matching QoS rule is found, the UE discards the uplink data packet.

2. The UE binds the QoS flows to radio bearers. The mapping of QFIs to radio bearers is done based on the signaling that the UE receives from the gNodeB over the NG-RAN interface.

3. These QoS profiles determine the characteristics of every QoS flow by setting the corresponding QoS parameters for each flow.

4. The gNodeB also maps every QoS flow (identified by its QFI) to a certain DSCP value, according to the 5QI value configured for this flow in the gNodeB QoS profile.

5. As shown in the figure above, inside each PDU session, the gNodeB does the following, according to the configured QoS profile:

- Signals the mapping between the QFIs and the radio bearers to the UE.
- Maps one or multiple radio bearers to the single NG-U tunnel of the PDU session between the gNodeB and the UPF.

In the downlink direction, the QoS flow-mapping process is the following:

1. The UPF maps the downlink user plane traffic to QoS flows based on matching downlink packets against downlink packet filters in the SDF template received from the SMF.

2. As shown in the figure above, the UPF transmits all flows of a PDU session in a single NG-U tunnel. The UPF includes the QFI in the tunnel encapsulation header.

3. For every QoS flow, the SMF determines the transport DSCP marking value based on the 5QI, and provides the transport level packet marking value to the UPF.

4. The UPF marks the downlink traffic with the transport DSCP on a per QoS flow basis, based on the transport DSCP marking value provided by the SMF.

5. The gNodeB maps one or multiple QoS flows from the NG-U tunnel to one or more radio bearers, according to the configured QoS profile, as shown in the figure above.

The figure below shows an example where multiple DRBs are carried within one PDU session.

![Image](../images/324_22112-IPM10141_100Uen.AU/additional_3_CP.png)

Figure 14   Example with Multiple DRBs per PDU Session

When deploying multiple DRBs per PDU session on a gNodeB, the following capabilities and system limitations must be considered:

- A UE supports up to 8 PDU sessions
- A PDU session supports up to 4 DRBs (Radio Bearers)
- A UE supports up to 8 DRBs
- One QoS flow per DRB

In the gNodeB, there is a predefined 5QI to DSCP mapping but it is also possible to configure different 5QI to DSCP mappings for all 5QIs. For the UL, the gNodeB applies one DSCP value per QoS flow.

In the downlink direction, it is assumed that the deployed SMF and UPF support the establishment of multiple QoS flows per PDU session from the 5GC side, where the UPF marks traffic with different DSCP values according to the 5QI to DSCP mapping configured in the SMF.

Because a gNodeB can have a single QoS flow per DRB, the support of multiple DRBs per PDU session becomes mandatory for some use cases, such as the Voice over NR (VoNR), where the setup of GBR QoS flow for voice using a dedicated DRB is required in the IMS PDU Session.

For more information about the setup of DRBs and PDU Sessions, including network impact and limitations for the NR SA Data Transfer, see NR Standalone.

### 2.3.2 5G QoS Parameters

The figure below summarizes the mandatory and optional 5G QoS parameters for both the GBR and the non-GBR 5G QoS flows.

Figure 15   5G QoS Flow Parameters

The QoS parameters take effect at the end of the following process:

1. The QoS parameters are authorized by the PCF according to the configured PCC rules.

2. The PCF sends these PCC rules to the SMF, including the QoS settings.

3. The SMF sends these QoS parameters to the UPF.

4. These parameters take effect on the uplink and downlink user plane traffic.

For the gNodeB, only manual configuration of the QoS profile is supported. These configurations include QoS parameters shown in Table 5, depending on the type of the QoS flow.

The 5QI parameter is the most important when mapping the 5G QoS parameters to the transport network QoS parameters.

#### 2.3.2.1 5QI

A 5QI is a scalar that is used as a reference to certain 5G QoS characteristics.

The characteristics associated with every 5QI value describe the packet forwarding treatment that a QoS flow receives end-to-end between the UE and the UPF in terms of the following performance characteristics:

Resource Type

Determines the type of the 5G QoS flow. Both GBR and non-GBR flows are supported in NR, along with the delay-critical GBR defined in the 5G QoS framework.

Delay-critical GBR resource types have stricter Packet Delay Budget (PDB) and Packet Error Rate (PER) requirements than those of the normal GBR resource types. The Maximum Data Burst Volume (MDBV) parameter applies only to the delay-critical GBR resource type.

Priority Level

The Priority Level associated with a 5QI value indicates a priority in scheduling resources among QoS flows. The lowest Priority Level value corresponds to the highest priority.

The Priority Level can be used to differentiate between QoS flows of the same UE and between the QoS flows of different UEs.

PDB

Defines an upper bound for the time that a packet can be delayed between the UE and the UPF. For every 5QI value, the value of the PDB is the same on the uplink and the downlink.

PER

Defines an upper bound for the rate of PDUs (for example, IP packets) that have been processed by the sender of a link layer protocol (for example, RLC in RAN), but that are not successfully delivered by the corresponding receiver to the upper layer (for example, PDCP in RAN). This way, the PER defines an upper bound for a rate of non-congestion related packet losses.

Averaging Window

Each GBR QoS flow is associated with an Averaging Window. The Averaging Window represents the duration over which the GFBR and MFBR are calculated (for example, in the RAN, UPF, and UE).

Note:  The Averaging Window is only valid for the GBR resource type, including the delay-critical GBR.

MDBV

Each GBR QoS flow with the delay-critical resource type is associated with an MDBV. The MDBV defines the largest amount of data that the gNodeB can serve within a period of gNodeB PDB, that is, the gNodeB budget part of the PDB.

Note:  The MDBV is only valid for the delay-critical GBR resource type.

If no 5QI table and no default 5QI table are defined in MOs CUCP5qiTable, CUUP5qiTable, DU5qiTable, then the default MO values for the 5QI table parameters are used. It is recommended to define at least the default 5QI table.

### 2.3.3 QoS Mapping for 5QI and QCI to Transport

The gNodeB maps 5QI values to the transport DSCP. In the 5G Core, the mapping of the 5QI to the DSCP is done by local configurations on the SMF. The SMF then provides the UPF with these transport DSCP mapping values, which marks the downlink traffic with the transport DSCP value on a per QoS flow basis.

Standardized 5QI values are specified for services that are assumed to be frequently used and this way benefit from optimized signaling by using standardized QoS characteristics. The one-to-one mapping of standardized 5QI values to 5G QoS characteristics is specified in 3GPP TS 23.501, System architecture for the 5G System (5GS).

#### 2.3.3.1 Mapping between 5QI and QCI

This section describes the mapping between 5QI and QCI which is needed for some use cases, for example:

- EN-DC
- EPS fallback
- 5GC-EPC intersystem handover
- Coexistence of NR NSA and NR SA in the same gNodeB

The 1:1 mapping between 5QI and QCI is standardized in 3GPP TS 23.502, Procedures for the 5G System (5GS), Annex C.

The EN-DC user plane traffic is transported over the S1 interface through E-RABs. Each E-RAB has a QCI assigned to it when it is set up with S1AP signaling. The QCI defines the QoS characteristics for the data transported over the E-RAB.

In an EN-DC network, the eNodeB and gNodeB nodes maps QCI to DSCP and P-Bit values.

For the eNodeB, the operator can configure the mapping from QCI to DSCP, and it is recommended to configure the QCI to DSCP mapping as defined in  Recommended Mappings of 5QI and QCI to DSCP as well as in  QoS Mapping for the Transport Network.

For the gNodeB, the recommended QoS mapping for QCI to DSCP as defined in  Recommended Mappings of 5QI and QCI to DSCP and  QoS Mapping for the Transport Network is available by default.

The gNodeB does a 1:1 mapping of a QCI to a 5QI, that is, a QCI=x is treated as a 5QI=x. If a 5QI to DSCP mapping is required as defined in  Recommended Mappings of 5QI and QCI to DSCP and  QoS Mapping for the Transport Network, this is available by default. If a 5QI to DSCP mapping is required that is different to the recommended QoS mapping, then this is possible by configuring an additional default QoS mapping. For more detailed information about this mapping, see NR DSCP Mapping Based on 5QI and QCI.

The S1AP and X2AP messages that are transported over the SCTP protocol, which is encapsulated in IP packets, are mapped to DSCP 40, see  QoS Mapping for the Transport Network for the recommended mapping.

For other types of non-radio signaling and control traffic, see  Common Support Services QoS.

On the SMF it is recommended to perform a 1:1 mapping between 5QI and QCI, which applies in some interworking cases between EPS and 5GS. With this handling, the gNodeB and SMF provide the same QoS treatment in NR NSA and NR SA sessions for specific services.

In specific cases, different network nodes or functions need to do the mapping between the 5QI and the QCI. Because of this, both values must be configured and aligned.

The 5GC-EPC intersystem handover is triggered in the NG-RAN, for example, when losing NR coverage during a data session. The NG-RAN initiates the transfer of all PDU sessions from the 5GC to the EPS. All flows in the established PDU sessions are transferred between the AMF and the MME, using intersystem handover signaling over the N26 interface.

The SMF and the UPF ensure IP address preservation and QoS mapping between the 5QI and the QCI for the flows in the established PDU sessions. The handover from the EPS to the 5GS follows the same procedures.

The EPS fallback is triggered when a UE is in the LTE and NR coverage, and tries to establish a QoS flow for voice in NR. That is, the UE requests a QoS flow with a 5QI value of 1 within a pre-established PDU session to the 5GC.

When the 5G system does not support Voice over NR, the voice needs to be supported by the VoLTE through the LTE service by falling back from NR to LTE. Therefore, the gNodeB rejects this QoS flow setup and triggers an EPS fallback request to the AMF. The re-establishment of the voice call is conducted through the N26 interface between the AMF and the MME.

The AMF needs to map the 5QI to the QCI when communicating with the MME, according to the received PCC rules.

In this case, the same gNodeB serves both NSA and SA UEs at the same time.

Each type of NSA and SA UEs have separate sessions to the Core. The NSA UEs are connected over EN-DC bearers to the 5G EPC, while the SA UEs are connected over 5G flows to the 5GC.

The gNodeB has a single table configuring all 5QI, QCI, and transport QoS mappings.

#### 2.3.3.2 Recommended Mappings of 5QI and QCI to DSCP

It is recommended that the operator applies default mappings between QCI, 5QI, and DSCP.

The default mappings are already pre-configured in the gNodeB as defined in the figure below and  QoS Mapping for the Transport Network. For more information, see NR DSCP Mapping Based on 5QI and QCI.

For the S1AP and X2AP messages, that are transported over the SCTP protocol, which is encapsulated in IP packets, see  QoS Mapping for the Transport Network for the recommended mapping.

If different mappings are required than the recommended mappings, then the operator needs to configure these mappings.

The figure below shows the recommended mappings of 5QI (NR SA, NR NSA) and QCI (LTE, NR NSA) to DSCP.

Figure 16   Recommended Mappings of QCI and 5QI to Transport DSCP

The GNBCUUPFunction only supports the default CUUP5qiTable MO instance for NR NSA deployments, which means the same DSCP value is shared per QCI or 5QI for each PLMN in a shared RAN scenario. For more information, see Shared NR RAN Solution Guideline, NR SA Network Slicing Guideline.

MBMS considerations

As the Release 15 of 3GPP TS 23.501, the system architecture for the 5G System (5GS), MBMS is not supported in the 5G system. No mapping is supported for the 5QI=75, since it is only used for the transmissions of the V2X messages over the MBMS bearers, as defined in 3GPP TS 23.285, Architecture enhancements for V2X services.

The gNodeB cannot configure the 5QI=75 value. Therefore, if a UE session is initiated over EN-DC with QCI=75, it is possible for the operator to configure a mapping of QCI=75 to a 5QI other than 75 during the handover to 5GC. This 5QI can be a standard 5QI or an operator-defined 5QI.

### 2.3.4 Scheduling for NR

#### 2.3.4.1 Overview

In NR, the gNodeB is responsible for scheduling in both downlink (DL) and uplink (UL) traffic. The gNodeB schedules the traffic for the DRB in DL with the NR schedulers and the priorities that are defined for the DRB. For the UL traffic, the gNodeB schedules traffic per UE. The priority of the UL traffic depends on the QoS parameters that determine the scheduling priority computed by the scheduler, and the triggers that grant the resources, such as the Scheduling Request (SR), the Buffer Status Reporting (BSR), and the Logical Channel Prioritization (LCP). For more information about these mechanisms, see  Service Differentiation in Uplink Scheduling.

A lot of algorithms for QoS-based scheduling are supported in the NR deployments. They can be broadly categorized into two operations: Priority-Controlled operation and Priority Domain-Shift operation.

Priority-Controlled Operation

- Priority-Controlled Scheduling: This algorithm serves as the foundation for other priority-based algorithms by mapping QCI and 5QI priority levels to the priority domains of the gNodeB. It ensures that services with higher priority have a greater scheduling weight, benefiting the use cases like mission-critical services coexisting with eMBB networks. For more details, see Priority-Controlled Scheduling.
- NR Relative Priority Scheduling: This offers a more granular priority adjustment within a Priority Domain. It can work independently or alongside Priority-Controlled Scheduling, enabling proportional resource distribution among various MBB services or 5QIs. For more information about use case examples, see NR Fixed Wireless Access Solution Guideline or 5G Voice SA RAN Solution Guideline.

Priority Domain-Shift Operation

- NR Rate-Controlled Scheduling: This allows operators to set a rate threshold per QoS flow to manage priority domain-shifts, benefiting services requiring specific throughput, like video streaming or online gaming. It consists of two operations, the Prioritized Rate operation and the Soft Rate Throttling operation. For more information, see NR Rate-Controlled Scheduling.
    - In the Prioritized Rate operation, traffic is served with high priority up to a configured rate, while the traffic above the configured rate is served with the default priority.
    - In the Soft Rate Throttling operation, traffic is served with default priority up to a configured rate, while traffic above the configured rate is served with a lower priority.
- NR Delay-Controlled Scheduling: This introduces priority shifts based on the packet delay. It allows operators to change scheduling priorities by enabling elevation time scheduling operation and maximum waiting time operation. For more details, see NR Delay-Controlled Scheduling.
    - In the elevation time scheduling operation, when the packet delay exceeds an elevation time configured for the DRB, the priority is elevated. This helps to prioritize delay-sensitive users only when necessary to ensure spectrum efficiency and benefit eMBB user performance. Because the delay-sensitive users are shifted to high priority only when the elevation time is exceeded.
    - In the maximum waiting time operation, it helps to prevent the starvation of low-priority services. This maximum waiting time mechanism is applicable to all DRBs within the cell. This raises the priority of any DRB if it remains unscheduled beyond this threshold. This operation applies across all scheduling algorithms when this algorithm is co-existing with other scheduling algorithms.
- Latency-Prioritized Scheduling: This algorithm aims to improve delay performance for delay-sensitive traffic flows. When the RLC packet is older than the age threshold (RAN PDB subtracting Priority Shift Margin), this algorithm elevates the priority domain for the corresponding DRBs. This algorithm benefits the use cases like online gaming or AR applications. For more information, see Latency-Prioritized Scheduling.

The scheduling in NR is to balance the diverse needs of services and users, ensuring the resources to be allocated effectively and efficiently. However, prioritizing certain high-QoS services might cause excessive spectrum consumption, potentially starving other lower-priority users and affecting the overall gNodeB performance. To address this challenge, several resource control mechanisms are supported:

- Resource Starvation Prevention in NR Rate-Controlled Scheduling: When a UE is configured with NR Rate-Controlled Scheduling and encounters suboptimal radio channel conditions, there is a risk of excessive spectrum utilization. UE might be stuck in the elevated priority domain and potentially starves others with the default priority domain. To address this issue, NR Rate-Controlled Scheduling introduces a resource limit, acting as an upper bound that can be applied at both DRB and cell levels. For more information, see NR Rate-Controlled Scheduling.
- Resource Control in Latency-Prioritized Scheduling: The Latency-Prioritized Scheduling can offer a higher scheduling weight of the configured QoS flows compared to other algorithms. However, this might lead to excessive resource consumption which can starve other users. Moreover, in certain situations, such as poor channel conditions, delay performance cannot be guaranteed even if the DRB is shifted to a higher priority domain. To mitigate this, Latency-Prioritized Scheduling introduces a resource control mechanism to reduce the priority when too many resources are consumed by a bearer configured to use the feature. For more information, see Latency-Prioritized Scheduling.
- Scheduling with NR Radio Resource Partitioning (RRP): An additional strategy is to prevent resource starvation for lower-priority services by deploying NR RRP. This mechanism works alongside features like NR Delay-Controlled Scheduling and Latency-Prioritized Scheduling, providing a two-level hierarchical prioritization. The first level is controlled by RRP, focusing on partition utilization. The second level is governed by 5QI, based on scheduling algorithms and related configurations. For more information, see Scheduling Order for QoS Flows According to QoS and NR RRP.

#### 2.3.4.2 Basic Scheduling Algorithms

##### 2.3.4.2.1 Priority-Controlled Scheduling

The Priority-Controlled Scheduling feature enables the gNodeB to perform Absolute Priority Scheduling on the NR radio bearer level for different sets of users, and between different Data Radio Bearers of a UE.

The priority-controlled scheduling function of the gNodeB is an Absolute Priority Scheduling function that schedules NR radio bearers with a higher absolute priority, before bearers with a lower absolute priority.

The priority of a bearer is defined by the priority of its Priority Domain, where the Priority Domain is derived by the Priority Level that is defined for the 5QI for the bearer.

![Image](../images/324_22112-IPM10141_100Uen.AU/additional_3_CP.png)

Figure 17   Priority Controlled Scheduling Principle

When deploying this function, the operator configures how Priority Levels (PLs) are mapped to different Priority Domains (PD), that is, each PD value is defined by a list of one or more PLs. A lower PD value corresponds to a higher priority.

|   Priority Domain | Priority Levels List   |
|-------------------|------------------------|
|                32 | 4, 5, 6, 7, 8          |
|                34 | 10, 11, 18, 19, 20, 21 |
|                38 | 55, 60                 |
|                44 | 65, 66, 67, 68         |
|                46 | 78, 79                 |
|                50 | 90                     |

For the PLs that do not have a configured mapping to a PD, the gNodeB applies the default mapping to the PD value 48.

- The gNodeB applies Absolute Priority Scheduling for the defined PDs.
- If an operator defines slices (resource partitions per S-NSSAI or PLMN-ID), see the NR SA Network Slicing Guideline for the 5QI to DSCP mapping.
- If service differentiation for different radio bearers in the UL traffic is important, then the operator must define the LCGs so that affected Priority Levels are mapped to different LCGs. If the operator does not configure any mapping from Priority Level to Priority Domain on a gNodeB, then all radio bearers have the priority that is defined for PD 48. This also means that there is no absolute priority differentiation for the radio bearers.

![Image](../images/324_22112-IPM10141_100Uen.AU/additional_3_CP.png)

Figure 18   Priority-Controlled Scheduling

The operator can enable or disable priority differentiation between Priority Levels as required. This means that the operator has control over when and how to apply absolute priority differentiation. Absolute priority must be used carefully because it can cause starvation of lower priority bearers. Therefore, it is only suitable for services with limited resource demands. A typical use case is the voice service, where Session Initiation Protocol (SIP) call control signaling, and Real-Time Transport Protocol (RTP) voice packets are prioritized.

The figure below shows the MO QoSPriorityMapping defines the default domain. Whereas MOs PriorityDomainMapping define the mapping of the priorityLevelsList per priorityDomain. In this example, the default 5QI table, 5QI 6, is mapped to the priority domain 45, and 5QI 9 is mapped to the priority domain 46. All other 5QI values are mapped to the default priority domain 48.

![Image](../images/324_22112-IPM10141_100Uen.AU/additional_3_CP.png)

Figure 19   Priority-Controlled Scheduling Setup

For more information about the feature description, see Priority-Controlled Scheduling.

##### 2.3.4.2.2 NR Relative Priority Scheduling

The NR Relative Priority Scheduling feature has no feature dependency to the Priority-Controlled Scheduling feature. It is possible to apply the NR relative priority scheduling function without applying the priority-controlled scheduling function.

The NR relative priority scheduling function enables the gNodeB to schedule the resources on NR based on the relative priority and the Packet Delay Budget (PDB) of each DRB within a priority domain. This enables an operator to prioritize traffic between different sets of users, and between different DRBs of a UE.

![Image](../images/324_22112-IPM10141_100Uen.AU/additional_3_CP.png)

Figure 20   NR Relative Priority Scheduling Principle

In short, the operator considers the following aspects when deploying this function:

- It selects services, for example, represented by 5QIs, that need prioritization to deliver the expected QoS to the user and which benefit from the NR relative priority scheduling.
- It configures the required NR relative priority for the Priority Levels (derived from 5QIs) within a Priority Domain. If multiple Priority Domains are defined, then the absolute priority scheduling (Priority-Controlled Scheduling) applies between the Priority Domains.
- If service differentiation for different DRBs in the uplink traffic is important, then the operator must define the LCGs so that affected NR Relative Priority Levels are the best possible.

When the NR Relative Priority Scheduling feature is active, specific services inside the same priority domain can be prioritized. Serving requirements with the necessary priority satisfies the needs of more users. The relative priority ensures a smoother impact on the low-priority users, with a lower risk of starvation.

For more information about the feature description, see NR Relative Priority Scheduling.

##### 2.3.4.2.3 NR Rate-Controlled Scheduling

If the resource contention occurs in the uplink or downlink or both of a cell, the NR Rate-Controlled Scheduling allows the operator to change scheduling priorities by introducing the possibility to configure a rate threshold for the QoS flow. This can support a priority domain shift in the NR scheduler.

This feature supports two scheduling operations, prioritized rate and soft-rate throttling. The figure below shows a configuration example including both operations.

- DRBs configured for the prioritized rate scheduling operation are scheduled with higher priority (Priority 45) until the threshold (the blue line) is reached. Once the scheduled rate is above the threshold, these DRBs are scheduled with default priority (Priority 48). By this operation, the scheduling rate for DRBs with high priority is secured to a prioritized rate.
- DRBs configured for the soft-rate throttling operation are scheduled with default priority (Priority 48) until the threshold (the green line) is reached. Once the scheduled rate is above the threshold, these DRBs are scheduled with lower priority (Priority 56). By this operation, the scheduling rate for DRBs with lower priority is limited to a certain scheduled rate if there is a resource contention.

![Image](../images/324_22112-IPM10141_100Uen.AU/additional_3_CP.png)

Figure 21   NR Rate-Controlled Scheduling Principle

During the resource contention for both operations, if the QoS flow rate is lower than the configured rate, the priority domain is shifted to the elevated priority domain. If the traffic flow rate is equal to, or higher than the configured rate, the priority domain is shifted to the demoted priority domain. Depending on the current QoS flow rate, the priority domain can toggle back and forth between the elevated priority domain and the demoted priority domain.

The elevated priority domain is configurable and determined by the PriorityDomainMapping MOC, which is described in the Priority-Controlled Scheduling feature. A range of priorities allows for service differentiation of the prioritized traffic.

The demoted priority domain is set to either HIGH or LOW:

- For prioritized rate operation, the HIGH setting means that the traffic is in the priority domain 48. The LOW setting means that the traffic is in the priority domain 52.
- For soft-rate throttling operation, the HIGH setting means that the traffic is only served if no other regular DRB traffic is ongoing. The LOW setting takes the lowest possible priority among the priority domains. This means that the soft-rate throttling traffic is only served if there is no other traffic ongoing.

The figure below shows the MO structure for Rate-Controlled Scheduling. The SchedulingProfile.schedulingAlgorithm attribute defines the prioritized rate or soft-rate throttling mode. Absolute and relative priority configurations define the QoS flow handling, as long as the rate does not reach the prioritized rate or soft-rate throttling rate.

![Image](../images/324_22112-IPM10141_100Uen.AU/additional_3_CP.png)

Figure 22   Rate-Controlled Scheduling with Resource Starvation Prevention MO Structure

The prioritized rate is configured with the DlRateBasedPriority.dlPrioritizedRate or UlRateBasedPriority.ulPrioritizedRate attributes as applicable for downlink or uplink, or both. In case the prioritized rate is reached for the QoS flow, the following attributes apply:

- DlRateBasedPriority.dlDemotedPriority
- DlRateBasedPriority.dlDemotedRelativePriority
- UlRateBasedPriority.ulDemotedPriority
- UlRateBasedPriority.ulDemotedRelativePriority

The feature is limited to two DRBs for each UE. Another DRB of a UE might attempt a setup with the feature. In this case, the DlRateBasedPriority.dlDrbOverloadHandling attribute and the UlRateBasedPriority.ulDrbOverloadHandling attribute can be used to configure the following actions:

- Set up the third DRB with the basic QoS.
- Reject the third DRB.

If the QoS flows prioritized by rate-controlled scheduling operations use the spectrum resources excessively in certain cases, such as in the poor radio conditions, it can cause the resource starvation.

To prevent this, the resource limit is added as an upper bound to the prioritized rate configured with the DlRateBasedPriority.dlPrioritizedRate and the UlRateBasedPriority.ulPrioritizedRate attributes. This resource limit can be differentiated on a DRB level and cell level.

Based on the value configured in the DlResourceBasedPriority.dlResourceLimitMode and UlResourceBasedPriority.ulResourceLimitMode attributes, the following resource limitation modes are possible:

- NO\_LIMIT (default setting)
- LIMITED
- LIMITED\_TO\_CELL\_LIMIT

For more information about parameter settings, see NR Rate-Controlled Scheduling.

Observability of Prioritized Rate Use

To gain insights about how often a DRB is handled differently because the UE already has two DRBs set up, the following events are counted:

- How often a DRB is set up with a prioritized rate or soft-rate throttling operation.
- How many times the third DRB is set up with basic QoS.
- How often the third DRB is rejected.

The following EBS counters are stepped when the setup or modification of a DRB with prioritized rate is allowed:

- pmEbsDrbEstabSuccSchdRate
- pmEbsDrbModSuccSchdRate

The following EBS counters show an increase when the third DRB of a UE with prioritized rate is rejected:

- pmEbsDrbEstabFailSchdRateReject
- pmEbsDrbModFailSchdRateReject

The following EBS counters are stepped when the third DRB with prioritized rate is allowed with basic QoS:

- pmEbsDrbEstabSuccSchdRateBasic
- pmEbsDrbModSuccSchdRateBasic

The following EBS-N counters provide observability to monitor the distribution of the ratio between the configured prioritized rate and the estimated maximum channel capacity:

- pmEbsnDrbPrioritizedRateChannelCapacityDlDistr
- pmEbsnDrbPrioritizedRateChannelCapacityUlDistr

Note:  When the resource-based priority limit is applied to the prioritized rate, the samples above the priority limit indicate that the prioritized rate used in the scheduling decision has been reduced from the configured prioritized rate to the scaled maximum channel capacity based on the priority limit.

Observability of Benefits

In downlink, the following throughput counters are used:

- NRCellDU.pmMacVolDlDrbQos
- NRCellDU.pmMacTimeDlDrbQos

In uplink, the following UE level counters can be used:

- NRCellDU.pmMacVolUlResUe
- NRCellDU.pmMacTimeUlResUe

If a UE has two or more slices (basically two different DRBs), following DRB level counters can be used for the uplink observability:

- NRCellDU.pmEbsnMacVolUlResDrb
- NRCellDU.pmEbsnMacTimeUlResDrb

The following PM Events provide more detailed analysis:

- For downlink, the DuPerUeRbTrafficRep event contains information to calculate the reported throughput on a per-second per-radio-bearer basis. Offline analysis is necessary to see on a more detailed level, if the provided throughput exceeds the prioritized rate.
- For uplink, the DuPerUeTrafficRep event is used to analyze throughput on a UE-level. The DuPerUeRbTrafficRep, DuPerUeRbTrafficRepAggr10, DuPerUeRbTrafficRepAggr60 events can be used to analyze throughput on a DRB level. This report provides insights about the effect of the feature.

Observability of Conditions

If the prioritized rate is not met, the RF conditions of the UE might be insufficient to provide the prioritized rate, even with absolute prioritization. Alternatively, another DRB might have even higher priority.

A detailed analysis of the radio conditions is possible using the information available in the following PM counters:

- For downlink, NRCellDU.pmRadioSinrPdschDistr
- For uplink, NRCellDU.pmRadioSinrPuschDistr

The NRCellDU.pmRadioSinrPdschDistr and NRCellDU.pmRadioSinrPuschDistr counters can be obtained from the DuPerRadioUeMeasurement PM Event.

The Signal-to-Interference-and-Noise Ratio (SINR) distribution can be mapped to the maximum theoretical channel capacity. If this capacity is below the prioritized rate, it is impossible for the UE to get the prioritized rate. This is the case even if the system provides all resources to the UE.

If rate-controlled scheduling for a prioritized rate is only needed in one direction, for example DL only but not for UL, and UlRateBasedPriority MO instance is not configured. In that case it is recommended to configure the SchedulingProfile.ulSchedulingAlgorithm attribute RESOURCE\_FAIR and not use PRIORITIZED\_RATE, since rate-controlled scheduling shall not be used for UL traffic. The rate-controlled scheduling is used only for the DL. Otherwise it results that default values to the UlRateBasedPriority MO are implicitly applied, which means ulPrioritizedRate = 1 kbps + ulDemotedPriority = HIGH. This means that the QoS flow is always scheduled in a demoted state as 1 kbps is likely always achieved.

Note:  Interaction with FR1-FR2 NR-DC. With the data aggregation, the FR1 leg might get small amounts of data because it is relative to the bandwidth. As only FR1 leg is considered in the rate estimation, and the rate estimation is underestimated, giving this QoS flow an elevated priority. However, it does not get much data on this leg, so it is unlikely to reach its prioritized rate. It therefore stays in an elevated state and consumes a lot of the PDCCH resources.

For more information about the feature description, see NR Rate-Controlled Scheduling.

##### 2.3.4.2.4 NR Delay-Controlled Scheduling

The NR Delay-Controlled Scheduling feature introduces a dynamic shift of the Priority Domain based on the delay of the packet, which is the elevation time scheduling operation. Compared to absolute priority scheduling which always uses high priority, the feature applies high priority when needed.

![Image](../images/324_22112-IPM10141_100Uen.AU/additional_3_CP.png)

Figure 23   Elevation Time Operation Principle

The feature includes support for cell-wide maximum waiting time operation. The key difference to elevation time operation is that it is applicable to all DRBs of the UEs in the cell. It is a safety function for the cell traffic to protect against negative side effects of DRBs with higher priority which might starve other traffic. The threshold is configured on cell level.

![Image](../images/324_22112-IPM10141_100Uen.AU/additional_3_CP.png)

Figure 24   Max Time Operation Principle

The figure below shows the MO structure for Delay-Controlled Scheduling. In the SchedulingProfile MO with parameters schedulingAlgorithm for downlink or ulSchedulingAlgorithm for uplink, the scheduling algorithm ELEVATION\_TIME can be configured per QoS flow.

![Image](../images/324_22112-IPM10141_100Uen.AU/additional_3_CP.png)

Figure 25   Delay-Controlled Scheduling MO Structure

The MOs DlDelayBasedPriority and UlDelayBasedPriority define the parameters, dlDemotedPriority and ulDemotedPriority, the priority domain is used for scheduling as long as the threshold values defined in CellPriorityShift with parameters cellDlElevationTime and cellUlElevationTime are not reached.

The demoted priority domain is set to either HIGH or LOW:

- For elevation time operation, the HIGH setting means that the traffic is in the priority domain 48. The LOW setting means that the traffic is in the priority domain 52.

The elevated priority domain is configurable and determined by the PriorityDomainMapping MOC, which is described in the Priority-Controlled Scheduling feature. A range of priorities allows for service differentiation of the prioritized traffic. The elevation time threshold is a cell specific configuration (it is applied to DRBs in the cell).

If a DRB is not scheduled because all resources are constantly used by the higher priority traffic, the RLC triggers a radio link failure for this DRB. To improve this situation, the maximum waiting time operation is introduced.

If the maximum waiting time threshold is reached for a DRB, the priority is elevated. The MO CellPriorityShift contains parameters for cellDlMaxWaitingTime and cellUlMaxWaitingTime to define the threshold. The elevated PD for MWT is either HIGH (PD4) or LOW (PD22) and is defined by parameters cellMwtDlElevatedPriority and cellMwtUlElevatedPriority.

The value of the maximum waiting time needs to be set in relation to the poll retransmit and maximum retransmission timer. The protection goal is that the maximum waiting time for a DRB is reached before the RLC layer triggers RLF.

An example case for using the Delay-Controlled Scheduling is described in the 5G Voice SA RAN Solution Guideline. The voice or any other traffic might be scheduled in the elevated PD, whereas the Internet traffic might suffer starvations if the resources are not left and the maximum waiting time is not configured.

##### 2.3.4.2.5 Latency-Prioritized Scheduling

The Latency-Prioritized Scheduling is designed for delay-sensitive services. It allows for dynamic shifting between demoted and elevated priority domains for the QoS flows based on the age of the oldest RLC packet. When the RLC packet is older than the priority shift threshold, this algorithm is allowed to elevate the priority domain.

- Priority Shift Threshold = RAN PDB - Priority Shift Margin

When too many resources are consumed by a bearer configured to use this feature and the resource control is triggered, the demoted priority domain is selected and the scheduling weight is reduced.

Note:  Resource control is configured per DRB but performed at the UE level when its multiple DRBs use this feature. The smallest resource control level among those DRBs (not including the Level 0) is applied to the UE.

This feature has two variants:

- Latency-Prioritized Scheduling
- Latency-Prioritized Scheduling for Time Critical Communication

The figure below shows a configuration example of Latency-Prioritized Scheduling with a user-defined 5QI (5QI=x). This configuration involves the RAN PDB (≥30 ms) combined with the Priority Shift Margin (≤ 0 ms) to facilitate dynamic priority domain shifts at or after the RAN PDB. Therefore, the priority shift threshold is equal to or greater than the RAN PDB. In this case, the demoted priority is restricted to Low (PD=48), and additional parameters such as the Priority Scaler (≤2) and the Weight Offset (ZERO) must be applied.

![Image](../images/324_22112-IPM10141_100Uen.AU/additional_3_CP.png)

Figure 26   Example of Latency-Prioritized Scheduling Configuration for 5QI=x

For more information, see Latency-Prioritized Scheduling.

The figure below shows a configuration example of Latency-Prioritized Scheduling for Time Critical Communication with 5QI=84. The priority shift margin offers more flexibility, allowing it to be greater than, less than, or equal to the configured RAN PDB. This permits dynamic priority domain shifting before, at, or after the RAN PDB. In this case, demoted priority can be set to either LOW (PD=48) or HIGH (PD=44) with the Priority Scaler (≤8). The Weight Offset can be set to ZERO, LOW, MEDIUM or HIGH.

![Image](../images/324_22112-IPM10141_100Uen.AU/additional_3_CP.png)

Figure 27   Example of Latency-Prioritized Scheduling for Time Critical Communication for 5QI=84

Note:  The priorityDomain=29 shown in the figure above serves as an illustrative example for configuration purposes. Operators need to customize the priority domain values to align with their specific design requirements and priority level settings.

The figure below shows a comparison between Latency-Prioritized Scheduling and NR Delay-Controlled Scheduling.

Figure 28   Latency-Prioritized Scheduling and NR Delay-Controlled Scheduling

For more information, see Latency-Prioritized Scheduling or Latency-Prioritized Scheduling for Time Critical Communication in the following libraries:

- Ericsson Critical IoT for Public RAN
- Ericsson Critical IoT for Dedicated RAN

#### 2.3.4.3 Scheduling with UE Grouping Framework

The UE Grouping Framework enables operators to manage and configure QoS parameters for specific UE groups. This framework supports the deployment of customized scheduling algorithms and different configurations for specific UE groups, thereby improving the overall scheduling efficiency and effectiveness.

UE Grouping Parameters

- NR SA UE Grouping:
    - 5QI
    - ARP
    - PLMN
    - RFSP
    - S-NSSAI
    - Masked IMEI-SV
    - CG Role
    - RRC establishmentCause
    - RRC resumeCause
    - RedCap UE
- NR NSA UE Grouping:
    - QCI
    - ARP
    - PLMN
    - SPID
    - Masked IMEI-SV
    - CG Role

For more information, see UE Grouping Framework.

Additional Features

When the UE Grouping Framework is activated, the NR Service-Adaptive Prescheduling can be used to enable prescheduling for each UE group. This feature reduces uplink delay for users within these groups and is applicable for both NR SA and NR NSA configurations. For more information, see NR Service-Adaptive Prescheduling.

#### 2.3.4.4 Scheduling with NR RRP

##### 2.3.4.4.1 Scheduling Order for QoS Flows According to QoS and NR
          RRP

In principle, the scheduler applies a two-level hierarchical prioritization when NR Radio Resource Partitioning (RRP) is used. The first level is RRP-controlled and depends on partition utilization. The second level is 5QI-controlled, and it depends on scheduling feature usage and related priority configurations.

The following example uses six UEs. For each UE, QoS is configured.

The green, orange, and purple UEs belong to resource partitioning as described in the NR Radio Resource Partitioning feature. The traffic of the black, blue, and dark blue UEs is on unallocated resources. The blue and dark blue UEs are configured for rate-controlled scheduling.

![Image](../images/324_22112-IPM10141_100Uen.AU/additional_3_CP.png)

Figure 29   QoS and RRP Configuration for UEs

The figure above shows the configured QoS and RRP for each UE. The green and orange UEs are configured with the Demoted-Normal RRP state. This means that when the RRP spectrum resource utilization is reached, the UEs enter the Demoted-Normal RRP state. In contrast, the purple UE is configured with the Demoted-Low RRP state. When the threshold is reached, it enters the Demoted-Low RRP state.

The traffic of the blue and dark blue UEs uses unallocated resources. The NR rate-controlled scheduling is configured with the demoted priority domain set to HIGH. This means that when the prioritized rate is reached, the traffic is scheduled in the default priority domain.

The figure below shows the RRP spectrum resource utilization for the green, orange, and purple UEs. For the blue and dark blue UEs, and the configured prioritized rate for rate-controlled scheduling.

![Image](../images/324_22112-IPM10141_100Uen.AU/additional_3_CP.png)

Figure 30   RRP Spectrum Resource and Prioritized Rate Utilization

The figure below shows the scheduling order of each QoS flow of all UEs.

![Image](../images/324_22112-IPM10141_100Uen.AU/additional_3_CP.png)

Figure 31   Priority Scheduling Order

The first block of scheduled UEs belongs to the Elevated RRP state. This state includes all traffic configured with prioritized partition. The 5QI 9 QoS flow of the green UE does not yet reach the configured RRP share, therefore, it is also included. First absolute priority, then relative priority defines the scheduling order in the Elevated RRP state.

The second block of scheduled UEs belongs to the Demoted-Normal RRP state. This state includes all residual traffic from RRP. The orange UE with 5QIs 8 and 9 QoS flows already uses the configured RRP share, configured with the Demoted-Normal RRP state. Therefore, it is also included. First absolute priority, then relative priority defines the further scheduling order also in the Demoted-Normal RRP state.

The third block of scheduled UEs belongs to the Demoted-Low RRP state. Only the purple UE belongs to this block. The 5QI QoS flow 9 of the purple UE already reaches the configured RRP share and is configured with the Demoted-Low RRP state.

This example does not consider the NR QoS-Aware Downlink Carrier Aggregation feature. Because the QoS of the Advanced RAN Coordination (ARC) relation is adapted depending on the congestion feedback from the gNodeB of the SCell.

#### 2.3.4.5 Scheduling in Carrier Aggregation

By default, Carrier Aggregation (CA) on E5 maps all external CA traffic to the same default priority. The DRB-level QoS information in the SpCell is mapped with the default priority to the SCells in both inter-gNodeB CA and intra-gNodeB inter-Capacity Module CA use cases. This limits the QoS control of traffic on the E5 link and might result in throughput degradation or latency constraints. To improve the QoS control over the E5 link, the following features can be considered:

- NR QoS-Aware Downlink Carrier Aggregation
- NR Carrier Aggregation Scheduling Optimization for External SCells

##### 2.3.4.5.1 NR QoS-Aware Downlink Carrier Aggregation

This feature adds the QoS awareness in carrier aggregation over the E5 interface for each Advanced RAN Coordination (ARC) relation. More than one ARC relation can exist between two nodes.

The following functions depend on the selected configuration:

- Configuring a fixed priority for the external traffic in a SCell
- Supporting dynamic priority for the external traffic in a SCell
- Providing a QoS aware traffic differentiation for the external traffic in a SCell, based on the DRB priorities set in the SpCell

The figure below shows the MO structure of NR QoS-Aware Downlink Carrier Aggregation.

![Image](../images/324_22112-IPM10141_100Uen.AU/additional_3_CP.png)

Figure 32   MO Structure of NR QoS-Aware Downlink Carrier Aggregation

High priority traffic is expected to get higher throughput in the external SCell. The priority mode that the SCell uses when scheduling external data is configured using the ExtCaPriority.adjustedPriorityMode attribute.

The STATIC\_PRIO\_WITH\_POLICING and STATIC\_PRIO\_WITHOUT\_POLICING priority modes are static priorities for the ARC relation on the E5 interface.

The STATIC\_PRIO\_WITH\_POLICING is a priority mode with policing. In this mode, priorities below the configured ARC relation priority are restricted from scheduling in the SCell. The STATIC\_PRIO\_WITHOUT\_POLICING is a legacy behavior priority mode without policing.

The priority of the ARC relation is configured using the ExtCaPriority.priorityDomainBase attribute for the priority domain, and the ExtCaPriority.relativePriority attribute for the relative priority.

The DYNAMIC\_PRIO is a dynamic priority mode for the ARC relation. The priority of the E5 tunnel is configured by the minimum and maximum values for the priority domain and the relative priority. The minimum priority domain is 64. The maximum priority domain is configured using the ExtCaPriority.priorityDomainLimit attribute. The minimum relative priority is 1. The maximum relative priority is configured using the ExtCaPriority.relativePriorityLimit attribute.

The gNodeB of the SpCell sets the actual priority domain and the relative priority, depending on the congestion feedback from the gNodeB of the SCell.

The following values are set at cell level using the NRCellDU MO Class:

- Base priority domain
- Base priority limit
- Relative priority base
- Relative priority limit

This means that the setting is the same for all operators sharing the cell. Operators working with shared NR RAN can use similar priority domain mapping.

For the nodes where NR Carrier Aggregation Scheduling Optimization for External SCells feature is enabled and active, scheduling priority of external SCells is no longer controlled by NR QoS-Aware Downlink Carrier aggregation feature.

For more information about the feature description, see NR QoS-Aware Downlink Carrier Aggregation.

##### 2.3.4.5.2 NR Carrier Aggregation Scheduling Optimization for
          External SCells

The existing inter-capacity module CA is supported across a large range of deployment use cases where an E5 RTT latency is up to 900 µs. If the E5 RTT latency is very short (below 35 µs), enabling NR Carrier Aggregation Scheduling Optimization for External SCells feature can enhance the peak SCell throughput in the external SCells to match the peak SCell throughput of local SCells. It also supports the DRB-level QoS information to be transmitted over E5 from SpCell to the external SCells for more precise scheduling decisions.

The figure below shows some potential use cases where the very short E5 RTT latency is most likely to be fulfilled:

![Image](../images/324_22112-IPM10141_100Uen.AU/additional_3_CP.png)

Figure 33   Potential Use Cases where the Very Short E5 RTT Latency is Fulfilled

For the E5 link RTT requirements for Carrier Aggregation, see Advanced RAN Coordination.

For more information about this feature, see NR Carrier Aggregation Scheduling Optimization for External SCells.

#### 2.3.4.6 Service Differentiation in Uplink Scheduling

Uplink scheduling in 5G NR involves a coordinated process where UE requests resources using a Scheduling Request (SR), the gNodeB allocates those resources and gives UE an Uplink Grant for transmission. The UE manages its transmissions using Buffer Status Reporting (BSR) and Logical Channel Prioritization (LCP) to ensure efficient and prioritized usage of uplink channels.

![Image](../images/324_22112-IPM10141_100Uen.AU/additional_3_CP.png)

Figure 34   Uplink Scheduling Procedures

To differentiate services in the uplink transmission, the QoS Framework can be deployed as a foundation, assigning each service a dedicated QoS flow. This flow includes QoS parameters that control scheduling priority and other mapping relations, such as Logical Channel Groups (LCGs). The QoS-Controlled SR Scheduling in the QoS Framework can help adapt the scheduling priority of scheduling requests based on the DRBs of the UE, the uplink QoS for the UE with high-priority DRBs is maintained. The BSR reports are sent by UE to indicate the status of its buffer, which helps the gNodeB make informed decisions about resource allocation across multiple UEs. While the LCP focuses on prioritizing data within the UE. The LCP parameters, such as priority, prioritisedBitRate, and bucketSizeDuration, can be assigned for each logical channel to instruct the UE on how to prioritize different traffic types based on their QoS requirements.

In the following subsections, a high-level example use case is presented to illustrate how service differentiation can be achieved for normal data service and real-time media service in the uplink scheduling procedures.

QoS Framework with Priority-Controlled Scheduling

Based on the QoS Framework, different QoS flows can be configured for different applications or services. In this case, normal data service and real-time media service are configured with different QoS flow as follows:

- QoS Flow 1 for normal data service, 5QI=9, PL=90
- QoS Flow 2 for real-time media service, 5QI=7, PL=70

If Priority-Controlled Scheduling is used, scheduling priority differentiation is supported at the bearer level based on priority levels of the configured 5QI. The gNode does not use the 5QI priority level directly for the scheduling but uses the priority level to find the internal priority of gNodeB, that is, the priority domain.

The figure below shows the mapping of priority level to priority domain from QoS flows to DRBs:

- QoS Flow 1 (5QI=9, PL=90) is mapped to DRB 1 (PD=50)
- QoS Flow 2 (5QI=7, PL=70) is mapped to DRB 2 (PD=48)

![Image](../images/324_22112-IPM10141_100Uen.AU/additional_3_CP.png)

Figure 35   Mapping QoS Flows to DRBs

Note:  All priority levels that are not explicitly mapped to a priority domain are mapped to the default priority domain (PD=48).

Priority domains implement absolute priority between DRBs, so that if A is smaller than B, a connection using priority domain A always has a higher priority than a connection using priority domain B. In this case, DRB 2 with PD=48 has a higher scheduling priority than DRB 1 with PD=50, so the real-time media service has a correspondingly higher priority than the normal data service.

For more information, see QoS Framework and Priority-Controlled Scheduling.

Uplink Scheduling Priority for Scheduling Request

For uplink traffic, the gNodeB schedules traffic per UE. All received Scheduling Requests from UE start with the same priority and increase over time. If the priority is the same, the gNodeB decides which UE to schedule first in a round-robin manner. The gNodeB sends UL grant to UE based on its scheduling decisions.

The figure below shows the uplink scheduling priority among different DRBs. Typically, uplink scheduling always gives a very high priority to the PUCCH SR (see the orange line), which might affect other prioritized services, such as the real-time media service (DRB 2, PD=48) in this case. The QoS Framework feature supports the configuration of SR priority in uplink scheduling based on the QoS of the UE. If the feature is enabled, the initial priority for the uplink scheduling starts according to the active highest priority DRB of the UE and increases over time. This feature is enabled per UE group that is defined with the UE Grouping Framework feature. It is possible to configure the feature so that a DRB is only considered for SR priority if a conditional DRB is established.

![Image](../images/324_22112-IPM10141_100Uen.AU/additional_3_CP.png)

Figure 36   QoS-Controlled SR Scheduling

Note:  "DRB high" is the highest priority of the configurable DRB, while "DRB low" is the lowest priority. The lower the value, the higher the priority.

Enabling QoS-Controlled SR Scheduling enhances the ability to maintain QoS for UEs based on their QoS priorities. This improvement is expected to enhance the overall performance of prioritized services, especially in high-load scheduling use cases.

For more information, see QoS Framework.

Buffer Status Reporting

Buffer Status Reporting (BSR) is a mechanism by which the UE informs the gNodeB about the amount of data buffered and ready to be sent in its uplink. BSR helps the gNodeB in 5G to manage and schedule uplink resources efficiently to meet UE's current data transmission requirements.

The Logical Channel Group (LCG) inherits scheduling priority from the active radio bearer with the highest absolute priority in the LCG. Therefore, gNodeB looks at the LCG priority of the active DRB for each UE that triggers the BSR when making scheduling decisions.

The figure below shows that both the normal data service (QoS flow 1) and the real-time media service (QoS flow 2) are configured with LCG=5. Both services now belong to the same LCG, so LCG=5 inherits the highest absolute priority (PD=48).

![Image](../images/324_22112-IPM10141_100Uen.AU/additional_3_CP.png)

Figure 37   LCG Inherits highest priority domain (PD) of the LCs within the same LCG

Logical Channel Prioritization

The Logical Channel Prioritization (LCP) is defined in 3GPP 38.321 where,

- priority defines the Logical Channel priority for scheduling
- prioritisedBitRate and bucketSizeDuration together define the amount of data to be allocated in the next transmission for the Logical Channel

The figure below shows the mapping of DRBs to Logical Channels as follows:

- The DRB 1 with PD=50 is mapped to Logical Channel 1 (priority=x1, prioritisedBitRate=y1, bucketSizeDuration=z1)
- The DRB 2 with PD=48 is mapped to Logical Channel 2 (priority=x2, prioritisedBitRate=y2, bucketSizeDuration=z2)

![Image](../images/324_22112-IPM10141_100Uen.AU/additional_3_CP.png)

Figure 38   Mapping DRBs to Logical Channels

Note:  If LogicalChannelUeCfg::logicalChannelGroup is empty, then DU5qi::logicalChannelGroupId is used.

Before the Enhanced UE QoS Control in Uplink feature is supported, the LCP parameters are not configurable, the gNodeB defines either fixed or algorithm-based values. When this feature is activated, LCP-related parameters can be configured for the logical channels carrying different QoS flows, such as logicalChannelPriority, prioritisedBitRate (prioritisedBitRateFR2 for FR2), and bucketSizeDuration. As a result, more possibilities for service differentiation can be achieved for LC1 and LC2 based on their real needs.

For more information, see Enhanced UE QoS Control in Uplink.

### 2.3.5 NR QoS-Related Features and Interactions

#### 2.3.5.1 Voice over NR

The feature Voice over NR (VoNR) establishes QoS flows for voice on dedicated Data Radio Bearers (DRBs) in a PDU session for IMS services.

![Image](../images/324_22112-IPM10141_100Uen.AU/additional_3_CP.png)

Figure 39   Example with Dedicated Voice Flows for VoNR

A PDU Session for VoNR has at least two DRBs:

- One DRB carrying the default non-GBR QoS flow for SIP (IMS) signaling with a configured 5QI value of five.
- Another DRB carrying the GBR QoS flow for the conversational voice with a configured 5QI value of one.

Additional multiple DRBs for GBR and non-GBR flows can be set up simultaneously to an existing IMS PDU Session.

For the UL, the gNodeB maps each 5QI, that is defined per QoS Flow, to a DSCP. For VoNR calls, the 5QI=5 is for SIP signaling, which is mapped to DSCP 40. The 5QI=1 is for the voice and is mapped to DSCP as defined in  Recommended Mappings of 5QI and QCI to DSCP or  QoS Mapping for the Transport Network. For detailed information about this mapping, see the feature description for NR DSCP Mapping Based on 5QI and QCI.

For more information, see Basic Voice over NR.

#### 2.3.5.2 NR Dynamic QoS Modification

This feature allows the dynamic modification of the 5QI (for NR SA and NR DC), QCI (EN-DC), and the ARP parameters of the QoS profile. The feature is supported in NR SA, NR-DC, and EN-DC.

The dynamic modification of the already established QoS properties provides increased flexibility when changing the characteristics of the service provided for individual UEs.

Triggering Dynamic QoS modification has the following use cases:

- A user might request a temporary boost in performance for a certain period at a certain price. The boost is achieved by a core network initiated 5QI modification. For example, the default 5QI 9 QoS flow is modified to 5QI 8. In RAN, scheduling weights for 5QI 8 are higher compared to 5QI 9. Therefore, in cells with resource contention, the user experiences a better performance compared to the default 5QI.
- The data volume quota for a user is over-utilized to lower its priority.
- In mission-critical services, a first responder might be prioritized.

According to 3GPP, the modification request of QoS properties is rejected in the gNodeB if the values of the following attributes change because of the modification of the QoS properties:

In gNodeB for NR SA and NR DC:

- CUCP5qi.pdcpSnSize
- DrbRlcUeCfg.rlcSNLength
- CUCP5qi.rlcMode

In master node eNodeB for EN-DC:

- MOs QciProfilePredefined, QciProfileOperatorDefined with parameters pdcpSNLength, rlcMode, rlcSNLength

In secondary node gNodeB for EN-DC:

- CUCP5qi.rlcMode

For more information, see NR Dynamic QoS Modification.

#### 2.3.5.3 Scheduling Periodicity Configuration based on Service
        Needs

The NR Service-Adaptive SR Periodicity feature enables SR periodicity to be configured according to service needs. The preferred SR periodicity can be configured on the cell level to be adapted for a specific 5QI or a UE group. The feature is now supported for both NR Mid-Band and NR High-Band.

Different services have different needs when accessing the system by an SR. To guarantee the performance in different services, such as the VoNR, Critical IoT, or other use cases, SR periodicity needs to match the corresponding requirements. For example, an SR periodicity of 40 ms is recommended for the consideration of VoNR performance, UE battery saving, and resource usage. For detailed MOM architecture of VoNR service in an FDD or TDD cell, see 5G Voice SA RAN Solution Guideline.

Service-adaptive SR periodicity configurations can reduce the PUCCH decoding rate for non-critical services to prioritize PUCCH decoding on latency-critical services. For example, the Scheduler High-Band feature uses NR service-adaptive SR periodicity according to the configuration when the radio coverage of the UE is good. The UE is reconfigured to the maximum allowed SR periodicity when the coverage of the UE is limited.

For more information, see NR Service-Adaptive SR Periodicity.

#### 2.3.5.4 QoS and Downlink Multi-User MIMO Mid-Band
        Interaction

The Downlink Multi-User MIMO Mid-Band feature can improve cell capacity by co-scheduling UEs with the same frequency and time resources. The co-scheduling is considered as a pairing opportunity.

UEs are normally scheduled according to QoS and RRP priority as described in previous sections. However, if the Downlink Multi-User MIMO Mid-Band feature is enabled, the scheduler checks if there are UEs that can be paired on the same PRB according to the MU-MIMO selection criteria.

Therefore, scheduling is not only based on UE priority, but also on other pairing opportunities to maximize cell throughput with MU-MIMO.

## 2.4 QoS Mapping for the Transport Network

Without AQM Based Congestion Control for HSDPA (FAJ 121 1664) enabled, it is important to have WCDMA and LTE best effort traffic in separate queues.

Note:  For all queue use cases (six, four, or three) LTE non-GBR data is always in a separate queue if the AQM Based Congestion Control for HSDPA feature is not enabled. This is because of the behavior of LTE.

With the LTE feature "DSCP Mapping Based on ARP and QCI", the eNodeB takes both QCI and ARP into consideration when mapping to a DSCP value. Thus, two services with the same QCI value and different ARP can be mapped to two different Transport DSCP values if the operator wants to add more separation on the Transport network. However, the figure below is considering this LTE feature is deactivated.

For the NR NSA QoS mapping, the new QCIs introduced in 3GPP TS 23.203 Release 15, are mapped and highlighted in the figure below. For the signaling part, with option 3x, there is no impact on S1AP and X2AP.

The figure below shows the recommended Generic QoS Mapping.

Figure 40   Recommended Generic QoS Mapping

Even though DSCP 54 is classified as Local Use, RFC 2474 defines the Local Use as DSCP xxxx11 or DSCP xxxx01.

In the above figures, the non-GBR data traffic of LTE and HSPA cannot be mixed in the same queue. This is because LTE takes the available capacity from HSPA in a congested link.

The AQM Based Congestion Control for HSDPA feature solves the problem of WCDMA capacity starvation in a shared RAT scenario. This way HSPA and LTE non-GBR traffic can be combined in the same priority queue.

Note:  The AQM Based Congestion Control for HSPA feature is implemented in the downlink only. A design approach to overcome this can be an asymmetric QoS mapping design. It is assumed that separate priority queues are used for WCDMA and LTE data traffic in the uplink direction, while the priority queues are combined in the downlink direction.

Another approach when enabling the AQM Based Congestion Control for HSPA feature is to configure symmetrical mapping in the uplink and downlink, where both LTE and HSPA non-GBR traffic are combined in the same queue. This approach is based on the assumption that the amount of LTE and HSPA non-GBR uplink traffic is considerably low compared to the downlink traffic. Because of this, there is a low probability to have a congestion in the uplink direction.

## 2.5 Rate Adaptation by L4S

Many new applications within the area XR or AR, Mission Critical, Cloud Computing, and Online Gaming have stringent requirements defined for loss and latency. Meeting Service Level Agreements for these services with traditional transmission protocols is difficult. Low Latency Low Loss Scalable Throughput (L4S) is an IETF draft standard for supporting rate adaptation, where any node in the communication chain can mark IP packets to indicate congestion.

Real-time media applications are typically rate adaptive, meaning that they can reduce bit rate to meet stringent latency requirements if there is a congestion or fading. The RAN can be a major bottleneck in the network and the gNodeB is a good observation point for L4S. It can detect congestion even before it is visible in the delay jitter noise at the endpoints of the connection. The downlink and uplink L4S features involve internal measurements to detect or predict or indicate congestion to the real-time applications.

![Image](../images/324_22112-IPM10141_100Uen.AU/additional_3_CP.png)

Figure 41   Rate Adaptation by L4S

The L4S congestion detection and rate recommendation can be enabled per UE-group level. Only a specific QoS flow carrying time sensitive service traffic identified by 5QI = x should be enabled as L4S capable, while other QoS flows carrying non-time sensitive service traffic are still L4S disabled as the default setting.

For more information, see Solution Guideline for Real-Time Media Services in Public RAN.

# 3 Transport Network QoS Aspects

This section gives common recommendations for the Transport QoS, considering different transport technologies (IP and Ethernet).

The figure below shows an overview of the Traffic Management System, which is used to fulfill the Transport QoS requirements. The QoS aspects in the figure below are common for the different transport technologies.

![Image](../images/324_22112-IPM10141_100Uen.AU/additional_3_CP.png)

Figure 42   Generic QoS Traffic Management System

## 3.1 Packet Classification and Marking

Classification of incoming traffic into the network or node is key for the QoS function to behave as anticipated. Before any differentiated forwarding treatment can take effect, packets need to be classified. Classification is the process of grouping traffic flows requiring the same treatment or PHB.

From the transport network perspective, the traffic classification can be based on the different transport mechanisms. For the plain IP, the IP header DSCP field is used to mark packets. For the Ethernet, the 802.1Q PCP bit (also called P-Bit) in the VLAN field is used to mark frames.

For more information, see Manage Quality of Service.

## 3.2 Bandwidth Control

### 3.2.1 Shaping

The shaping function is used at the egress interfaces of network nodes. Shaping "even out" bursts in the traffic and improves the overall network utilization, while at the same time avoiding packet drops during the high bursts.

The parameters that can usually be configured are the bandwidth and the buffer size. As long as there is a room left in the buffer, the additional traffic can be accepted for sending, including bursts. Once the buffer is full, the newly arriving traffic will be dropped.

The shaping is important when the policing is being performed on the receiving end of a link. The traffic shaping is typically used to control the traffic output towards a leased line service. The shaping is even more important if the traffic is bursty and the policing limit is close to the expected traffic volume.

Note:  When a Cell Site Router (CSR) is connected to the high-capacity (100G) TN port of the RAN Compute Group 6, it is recommended to make the shaping configuration on the CSR port facing the RAN Compute Group 6 to a CIR of 50 Gbps and a CBS of 50 MB. This configuration helps to prevent large ingress bursts at line rate, which can cause traffic disturbances.

The following two subsections show two examples about how the shaping function can be used in the Baseband.

#### 3.2.1.1 Shaping at Baseband TN Port for SLA Compliance

In an E2E telecom network, the traffic originating from the Baseband nodes to the transport network (routers or switches), and finally entering the core network. To ensure the compliance with the Service Level Agreements (SLAs), appropriate QoS mechanisms must be consistently applied across the network segments.

Typically, the transport network nodes implement the traffic policing at the ingress points to prevent unintended bandwidth usage and to enforce the QoS profiles. For example, if the operator leases the backhaul network from another service provider, usually the service provider can only offer a certain bandwidth based on the SLA. In this case, the traffic shaping must be applied at the Baseband TN port (for example, the RAN Baseband towards a CSR) to match the policing parameters (might be configured on the CSR). This approach prevents traffic bursts, reduces packet drops, and ensures the E2E SLA criteria such as latency, jitter, and bandwidth guarantee.

#### 3.2.1.2 Shaping for Network Slicing

For the network slicing, it might be required to limit the bandwidth usage for a particular slice. The shaping can potentially be used for this type of use case. This can be achieved by attaching a shaper MO as the parent of a queue MO.

The figure below shows a high-level use case where the shaping is configured for different slices applied to a single Baseband TN port to manage egress traffic effectively:

- Default Slice (S-NSSAI=0): This slice handles the traffic for regular subscribers using a moderate 5G package. It supports all types of services (5QIs) without any traffic shaping, allowing for a balanced experience across various services.
- Premium Slice (S-NASSAI=1): This slice accommodates subscribers with the enhanced 5G packages. It can be used to prioritize the traffic for users with the premium subscriptions. The shaping configuration is optional for this slice.
- Special Service Slice (S-NASSAI=2): This is designed for a specific service with a bandwidth constraint, such as the camera monitoring traffic. This slice ensures that the special service is delivered effectively without exceeding the bandwidth limit.

![Image](../images/324_22112-IPM10141_100Uen.AU/additional_3_CP.png)

Figure 43   Shaping Configuration for Network Slicing

Note:  The above PCP-to-Queue mapping is just an example, the real mapping in the customer network might be different based on their specific requirements.

In this configuration, the EthernetPort::egressQosQueueMap is set to map the PCP values to queues for the default slice. The VlanPort::egressQosQueueMap is set to map the PCP values to queues for the premium slice and the special service slice.

Under the EthernetPort::QueueSystem MO, a SchedulerDwrr MO is created to manage the scheduling and shaping. The Shaper 1 (CIR=3Gbps) is allocated for the premium slice (S-NSSAI=1), and the Shaper 2 (CIR=1Gbps) is allocated for the special service slice (S-NSSAI=2).

The SchedulerDwrr::schedulingWeight is configured as 20:20:20:30:10 for the corresponding queues, reflecting how the TN port capacity is shared among these slices. This ensures that each slice has a proportionate share of the transport resources, optimizing its performance and reliability.

Note:  If the EthernetPort level aggregate shaping is required, a parent shaper (Shaper 3) with the CIR configuration can be added to the SchedulerDwrr (DWRR 1), and a parent SchedulerDwrr (DWRR 2) needs to be added to the Shaper 3 accordingly.

For more information about MoM and concepts, see Manage Quality of Service and Egress IP Traffic Shaping.

## 3.3 Queuing and Scheduling

### 3.3.1 Queuing

Queues are used to implement different forwarding treatments to different traffic flows inside transport equipment.

The number of transport equipment queues implies an upper limit on the number of treatment aggregates. They can be flexibly differentiated to fulfill requirements, for example sensitivity to delay, jitter, or packet losses. This must be considered generally in any QoS design.

Additional differentiation mechanisms, for example, drop precedence, can be used in specific cases, but the design must not rely on them. The design must remain valid if these additional mechanisms are removed.

Queue Depths

Each queue in a node has a limit on the number of packets or bytes that can be placed into the queue. This limit is the queue depth, and it is user configurable. During congestion, a queue starts to drop packets if one of the following events occurs:

- The queue fills to its maximum configured capacity in the tail drop.
- The queue fills to a predefined limit in the case of Random Early Discard (RED).

The queue depth is configured considering the following factors:

- Average packet size
- Available bandwidth
- Traffic shaper rate
- Allowed delay

The queue depth must be set using a balanced approach. Setting it too high results in a reduced packet buffer for other queues. It can also cause latency-sensitive traffic to be buffered for too long before it is scheduled for the transmission.

Depending on the node, the queue depth can be specified in bytes, number of packets, or maximum time in the queue.

The figure below shows a simplified recommended approach to the initial configuration of the queue depth.

Figure 44   Recommended Initial Configuration of Queue Depths

Note:  For RAN Compute Group 6, it is essential to use at least the default queue size for Queue 6~8 (not the recommended equation as shown above) to handle the increased node capacity and its potential burstiness of traffic and avoid the packet drops. For details on the default queue size, see Manage Quality of Service.

In the figure above, queues 1-5 have node delay requirements for each Class of Service.

The figure below shows the formula for calculating the recommended queue depth for the queue 1-5 classes of service.

Figure 45   Generic Queue Depth Calculation

The elements of the formula are the following:

- Queue Depth: The queue depth in bytes
- CIR: The effective transmit rate of the queue in bits per second
- Queue\_Delay: The maximum allowed time in the queue in seconds

Queue 6 does not have a specific delay requirement. The figure below shows the formula for calculating the recommended queue depth for the queue 6 class of service.

Figure 46   Modified Buffer Size Calculation

The elements of the formula are the following:

- Queue Depth: The queue depth in bytes
- CIR: The effective transmit rate of the queue in bits per second
- RTT: The average round-trip time for an E2E flow passing across the link. If unknown, it can be estimated as 50 ms.
- n: For backhaul routers, n is the number of TCP flows. It can be estimated as 30 flows per 100-Mbps CIR step. This means that, for example, n = 300 flows on a 1-Gbps aggregated capacity or CIR in the queue. For Baseband dimensioning, it is the average number of connected UEs to an RBS.

The figure above is based on the Reno TCP stack. However, almost all UE devices in mobile networks use the CUBIC stack instead. The CUBIC stack saves almost 50-60% on the router buffer sizes than the Reno stack. However, the figure above is still considered in the buffer sizing calculation to add some safety margin (the Reno stack equation is well-known and safe to use).

In Queue 5, RED must only be enabled if the AQM Based Congestion Control for HSDPA feature is enabled. If this feature is enabled and there is no NR traffic carried in this queue, then the queue can be merged as well with traffic from class of service 6.

The figure below shows a calculated queue depth example in RAN Compute Group 4/5, assuming a use case with the following values:

- For queue 1, 2, 3, the CIR is 100 Mbps
- For queue 4, 5, the CIR is 200 Mbps
- For queue 6, the CIR is 10 Gbps, n = 2000, and RTT = 50 ms

Figure 47   Queue Depth Configuration Example

Note:  For RAN Compute Group 6, it is essential to use at least the default queue size for Queue 6~8 (not the recommended equation as shown above) to handle the increased node capacity and its potential burstiness of traffic and avoid the packet drops. For details on the default queue size, see Manage Quality of Service.

### 3.3.2 Scheduling

The scheduling operation selects which queue is the next to forward a packet. Scheduling is required so that critical traffic (for example, network control) or delay sensitive traffic (for example, voice) is dispatched ahead of other traffic types in congestion situations.

For more information, see Manage Quality of Service.

## 3.4 Congestion Avoidance

Queue management (passive or active) and Explicit Congestion Notification (ECN) can be used to prevent congestion. Tail Drop is a passive queue management mechanism and RED is an Active Queue Management mechanism.

For more information, see Manage Quality of Service.

# 4 Solution Guideline Change History

This section summarizes the major changes in this document release.

| Release   | Main Changes                                                                                                                                                      |
|-----------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| 25.Q2     | Add two high-level shaping configuration use cases for the Baseband TN port QoS.                                                                                  |
| 25.Q1.3   | Add Latency-Prioritized Scheduling and refine the scheduling algorithm overview and scheduling with UE Grouping Framework.                                        |
| 24.Q4     | Add high-level flow description of service differentiations in uplink scheduling and introduce NR Carrier Aggregation scheduling optimization for external SCells |
| 24.Q3     | Enhance UE QoS Control in Uplink by customizing the LCP priority parameters and update the queue depth calculation example in RAN Computer Group 4/5              |
| 24.Q2     | Enhance the Rate-Controlled Scheduling with the resource starvation prevention and add Rate Adaptation by L4S                                                     |
| 24.Q1.1   | Restructure the NR QoS Handling section                                                                                                                           |
| 24.Q1     | Add QoS and downlink Multi-User MIMO Mid-Band interactions, and the scheduling periodicity configuration based on service needs                                   |
| 23.Q4     | Add Delay-Controlled Scheduling                                                                                                                                   |
| 23.Q3     | Add Rate-Controlled Scheduling                                                                                                                                    |